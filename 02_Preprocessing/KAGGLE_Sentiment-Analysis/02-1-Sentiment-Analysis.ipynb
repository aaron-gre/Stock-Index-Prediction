{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12246385,"sourceType":"datasetVersion","datasetId":7716289},{"sourceId":12246570,"sourceType":"datasetVersion","datasetId":7716418}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Beispiel Sentiment Analysis","metadata":{}},{"cell_type":"code","source":"# PyTorch installieren\n#!pip install torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:40:06.461529Z","iopub.execute_input":"2025-07-02T20:40:06.462323Z","iopub.status.idle":"2025-07-02T20:40:06.466947Z","shell.execute_reply.started":"2025-07-02T20:40:06.462284Z","shell.execute_reply":"2025-07-02T20:40:06.465969Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"#Hilfscode zum finden meines Arbeitsverzeichnis und der vorhanden Dateien\nimport os\n\nprint(\"Aktuelles Arbeitsverzeichnis:\", os.getcwd())\n\ninput_dir = '/kaggle/input/'\n\nfor root, dirs, files in os.walk(input_dir):\n    print(f\"Verzeichnis: {root}\")\n    print(f\"Unterordner: {dirs}\")\n    print(f\"Dateien: {files}\")\n    print('---')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:40:06.479315Z","iopub.execute_input":"2025-07-02T20:40:06.479609Z","iopub.status.idle":"2025-07-02T20:40:06.520171Z","shell.execute_reply.started":"2025-07-02T20:40:06.479585Z","shell.execute_reply":"2025-07-02T20:40:06.519394Z"}},"outputs":[{"name":"stdout","text":"Aktuelles Arbeitsverzeichnis: /kaggle/working\nVerzeichnis: /kaggle/input/\nUnterordner: ['llm-text', 'llm-test-text']\nDateien: []\n---\nVerzeichnis: /kaggle/input/llm-text\nUnterordner: ['TEXT']\nDateien: []\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT\nUnterordner: ['EZB']\nDateien: []\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB\nUnterordner: ['17_October_2024', '17_April_2025', '14_December_2023', '11_April_2024', '12_December_2024', '21_July_2022', '08_September_2022', '14_September_2023', '12_September_2024', '07_March_2024', '27_October_2022', '16_March_2023', '06_March_2025', '26_October_2023', '27_July_2023', '25_January_2024', '02_February_2023', '30_January_2025', '18_July_2024', '05_June_2025', '09_June_2022', '15_December_2022', '15_June_2023', '04_May_2023', '06_June_2024']\nDateien: []\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/17_October_2024\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/17_April_2025\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/14_December_2023\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/11_April_2024\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/12_December_2024\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/21_July_2022\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/08_September_2022\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/14_September_2023\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/12_September_2024\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/07_March_2024\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/27_October_2022\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/16_March_2023\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/06_March_2025\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/26_October_2023\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/27_July_2023\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/25_January_2024\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/02_February_2023\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/30_January_2025\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/18_July_2024\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/05_June_2025\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/09_June_2022\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/15_December_2022\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/15_June_2023\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/04_May_2023\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-text/TEXT/EZB/06_June_2024\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-test-text\nUnterordner: ['TEXT_TEST']\nDateien: []\n---\nVerzeichnis: /kaggle/input/llm-test-text/TEXT_TEST\nUnterordner: ['17_October_2024', '17_April_2025', '12_December_2024', '12_September_2024', '06_March_2025', '30_January_2025', '05_June_2025']\nDateien: []\n---\nVerzeichnis: /kaggle/input/llm-test-text/TEXT_TEST/17_October_2024\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-test-text/TEXT_TEST/17_April_2025\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-test-text/TEXT_TEST/12_December_2024\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-test-text/TEXT_TEST/12_September_2024\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-test-text/TEXT_TEST/06_March_2025\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-test-text/TEXT_TEST/30_January_2025\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\nVerzeichnis: /kaggle/input/llm-test-text/TEXT_TEST/05_June_2025\nUnterordner: []\nDateien: ['3_ECONOMIC_ACTIVITY.txt', '5_PRESS_CONFERENCE.txt', '2_INFLATION.txt', '0_FULL.txt', '4_RISK_ASSESSMENT.txt', '1_CONCLUSION.txt', '6_FINANCIAL_MONETARY_CONDITIONS.txt']\n---\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# individual Models","metadata":{}},{"cell_type":"code","source":"#finbert single\nfrom transformers import pipeline\nimport os\nimport pandas as pd\nfrom datetime import datetime\n\n# OPTION: Ausgabe ein/ausschalten\nSHOW_PROGRESS = True  # Setze auf True für Fortschrittsanzeige\n\n# Model laden\nsentiment_analyzer = pipeline(\"text-classification\", model=\"ProsusAI/finbert\", top_k=None)\n\n# Pfad zu den Ordnern\ninput_folder = \"/kaggle/input/llm-text/TEXT/EZB\"\n\n# Alle Datums-Ordner durchgehen\ndate_folders = sorted([f for f in os.listdir(input_folder) if os.path.isdir(os.path.join(input_folder, f))])\n\nresults = []\n\nfor date_folder in date_folders:\n    conclusion_file = os.path.join(input_folder, date_folder, \"0_FULL.txt\")\n    \n    if os.path.exists(conclusion_file):\n        if SHOW_PROGRESS:\n            print(f\"Verarbeite: {date_folder}\")\n        \n        # Datei lesen\n        with open(conclusion_file, 'r', encoding='utf-8') as file:\n            text = file.read()\n        \n        # Text in Chunks aufteilen\n        chunks = [text[i:i+512] for i in range(0, len(text), 400) if len(text[i:i+512].strip()) > 50]\n        \n        # Chunks analysieren\n        optimism_scores = []\n        for chunk in chunks:\n            result = sentiment_analyzer(chunk)\n            \n            neg_prob = next(r['score'] for r in result[0] if r['label'] == 'negative')\n            pos_prob = next(r['score'] for r in result[0] if r['label'] == 'positive')\n            \n            optimism_score = pos_prob - neg_prob\n            optimism_scores.append(optimism_score)\n        \n        # Gesamtergebnis\n        overall_optimism = sum(optimism_scores) / len(optimism_scores)\n        \n        # Zeile für DataFrame vorbereiten - KORREKTE REIHENFOLGE\n        row = {'Date': date_folder}\n        for idx, score in enumerate(optimism_scores, 1):\n            row[f'Chunk_{idx}'] = round(score, 3)\n        row['Overall_Score'] = round(overall_optimism, 3)\n        results.append(row)\n\n# DataFrame erstellen\ndf = pd.DataFrame(results).fillna(0)\n\n\n# Spalten in korrekter Reihenfolge sortieren\nchunk_cols = [col for col in df.columns if col.startswith('Chunk_')]\nchunk_cols = sorted(chunk_cols, key=lambda x: int(x.split('_')[1]))\ncolumn_order = ['Date'] + chunk_cols + ['Overall_Score']\ndf = df[column_order]\n\n# Zeitliche Sortierung\ndef parse_date(date_str):\n    try:\n        parts = date_str.split('_')\n        if len(parts) == 3:\n            day, month, year = parts\n            return datetime.strptime(f\"{day} {month} {year}\", \"%d %B %Y\")\n        else:\n            return datetime.max\n    except:\n        return datetime.max\n\ndf['Parsed_Date'] = df['Date'].apply(parse_date)\ndf_sorted = df.sort_values('Parsed_Date').drop(columns=['Parsed_Date'])\n\n# Direkte Ausgabe\nprint(df_sorted.to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:40:06.521355Z","iopub.execute_input":"2025-07-02T20:40:06.522050Z","iopub.status.idle":"2025-07-02T20:40:17.239035Z","shell.execute_reply.started":"2025-07-02T20:40:06.522031Z","shell.execute_reply":"2025-07-02T20:40:17.238105Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Verarbeite: 02_February_2023\nVerarbeite: 04_May_2023\nVerarbeite: 05_June_2025\nVerarbeite: 06_June_2024\nVerarbeite: 06_March_2025\nVerarbeite: 07_March_2024\nVerarbeite: 08_September_2022\nVerarbeite: 09_June_2022\nVerarbeite: 11_April_2024\nVerarbeite: 12_December_2024\nVerarbeite: 12_September_2024\nVerarbeite: 14_December_2023\nVerarbeite: 14_September_2023\nVerarbeite: 15_December_2022\nVerarbeite: 15_June_2023\nVerarbeite: 16_March_2023\nVerarbeite: 17_April_2025\nVerarbeite: 17_October_2024\nVerarbeite: 18_July_2024\nVerarbeite: 21_July_2022\nVerarbeite: 25_January_2024\nVerarbeite: 26_October_2023\nVerarbeite: 27_July_2023\nVerarbeite: 27_October_2022\nVerarbeite: 30_January_2025\n             Date  Chunk_1  Chunk_2  Chunk_3  Chunk_4  Chunk_5  Chunk_6  Chunk_7  Chunk_8  Chunk_9  Chunk_10  Chunk_11  Chunk_12  Chunk_13  Chunk_14  Chunk_15  Chunk_16  Chunk_17  Chunk_18  Chunk_19  Chunk_20  Chunk_21  Chunk_22  Chunk_23  Chunk_24  Chunk_25  Chunk_26  Chunk_27  Chunk_28  Chunk_29  Chunk_30  Chunk_31  Chunk_32  Chunk_33  Chunk_34  Chunk_35  Chunk_36  Chunk_37  Chunk_38  Chunk_39  Chunk_40  Chunk_41  Chunk_42  Chunk_43  Chunk_44  Chunk_45  Chunk_46  Overall_Score\n     09_June_2022    0.028    0.754   -0.919   -0.943   -0.435   -0.920   -0.025   -0.002    0.476    -0.155     0.062     0.602     0.053     0.624     0.099     0.163     0.895     0.054     0.753     0.749    -0.936    -0.855    -0.880     0.908    -0.051     0.091     0.797     0.275     0.301     0.065    -0.942     0.636     0.874     0.865     0.923     0.916     0.884    -0.894    -0.890     0.880     0.937    -0.936     0.331    -0.739     0.674     0.314          0.119\n     21_July_2022    0.066    0.839    0.754    0.319    0.365    0.399    0.174    0.328    0.615     0.733     0.486     0.497     0.310     0.526     0.628     0.867     0.821     0.751     0.544     0.222     0.186     0.084    -0.960     0.898     0.903     0.900     0.556    -0.657     0.504     0.647    -0.918    -0.935    -0.825    -0.612    -0.927    -0.938     0.506     0.796     0.114     0.000     0.000     0.000     0.000     0.000     0.000     0.000          0.245\n08_September_2022    0.195    0.890    0.661   -0.877   -0.667   -0.950   -0.932    0.362    0.775    -0.040     0.178     0.168     0.451     0.797     0.314     0.878     0.769    -0.092    -0.853    -0.953    -0.949    -0.248     0.057     0.932    -0.916    -0.959    -0.538     0.905     0.925     0.701    -0.288     0.548    -0.414    -0.939    -0.926     0.380    -0.632     0.881     0.167     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.006\n  27_October_2022    0.367    0.779   -0.145    0.591    0.179    0.033    0.089    0.446    0.115     0.329     0.014     0.600     0.122     0.825     0.758    -0.589     0.325     0.258     0.021    -0.908    -0.963    -0.964    -0.897    -0.448     0.866     0.934     0.808     0.846     0.823    -0.942    -0.845    -0.626    -0.920     0.462     0.913     0.214     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000          0.096\n 15_December_2022    0.403    0.856    0.038   -0.963   -0.469    0.688   -0.910   -0.893   -0.948    -0.870     0.699    -0.962    -0.323     0.583     0.677     0.197     0.848     0.825    -0.961    -0.896     0.046    -0.899    -0.920    -0.958    -0.965    -0.093    -0.961    -0.843    -0.445     0.682     0.694    -0.817     0.138     0.934     0.929    -0.931    -0.813     0.330    -0.941    -0.859     0.605     0.899    -0.925    -0.357     0.068     0.000         -0.195\n 02_February_2023    0.136    0.787    0.424   -0.961    0.027    0.291    0.637   -0.940   -0.907     0.249     0.252     0.336     0.505     0.666     0.800     0.258    -0.917     0.189     0.127    -0.878    -0.950     0.883    -0.877     0.268     0.821     0.672    -0.912     0.792    -0.733     0.901     0.383    -0.495     0.803     0.680    -0.804    -0.955    -0.962    -0.449     0.788    -0.952     0.132     0.000     0.000     0.000     0.000     0.000          0.003\n    16_March_2023    0.106    0.718    0.727    0.075   -0.934   -0.856    0.265    0.764   -0.964     0.145     0.486     0.680     0.205     0.351     0.843     0.853    -0.006    -0.920    -0.813     0.859    -0.794    -0.941     0.932     0.736     0.609     0.818    -0.947     0.866     0.850    -0.680    -0.949    -0.606     0.418    -0.858    -0.760    -0.948     0.236     0.314     0.271     0.000     0.000     0.000     0.000     0.000     0.000     0.000          0.030\n      04_May_2023   -0.033    0.519    0.212    0.130   -0.065    0.661   -0.966    0.001    0.419     0.709     0.167     0.192     0.643     0.253     0.109    -0.049     0.929    -0.939     0.352     0.716     0.440    -0.819    -0.957     0.506     0.880    -0.848     0.714    -0.761    -0.923     0.931    -0.948    -0.389     0.617     0.247     0.419     0.096     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000          0.088\n     15_June_2023   -0.064    0.408   -0.486   -0.848   -0.339    0.139    0.077   -0.943   -0.959     0.166     0.514     0.791     0.172     0.610     0.432    -0.945    -0.887     0.178    -0.102    -0.895    -0.956    -0.773     0.914    -0.902    -0.949    -0.908     0.812    -0.945    -0.942     0.161    -0.860    -0.253    -0.942    -0.961    -0.919    -0.667     0.650     0.239     0.222     0.178     0.000     0.000     0.000     0.000     0.000     0.000         -0.270\n     27_July_2023   -0.003    0.672   -0.039    0.277    0.120    0.269    0.518   -0.961    0.151     0.185     0.766     0.221     0.713     0.892     0.712     0.253     0.693     0.113    -0.963    -0.894    -0.543     0.815    -0.888    -0.929     0.482    -0.770    -0.947    -0.574    -0.404     0.337     0.930    -0.879    -0.968    -0.962     0.532     0.246     0.167     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.018\n14_September_2023    0.009    0.890   -0.480   -0.935   -0.849    0.612    0.055    0.791   -0.964     0.384     0.707     0.338     0.117     0.896    -0.348    -0.788    -0.932     0.843     0.038    -0.950    -0.588    -0.861     0.797     0.861    -0.947    -0.959    -0.793    -0.961    -0.708     0.659     0.360    -0.516    -0.959    -0.961     0.896     0.406     0.163     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.126\n  26_October_2023    0.486   -0.697    0.854    0.116    0.019   -0.963   -0.758   -0.757    0.558     0.842    -0.963    -0.929    -0.963    -0.936    -0.933     0.525     0.420     0.544     0.928    -0.949    -0.964    -0.959    -0.615     0.846     0.146     0.044    -0.000     0.037    -0.087    -0.043     0.235     0.185    -0.104    -0.001     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.142\n 14_December_2023    0.003   -0.824    0.514    0.673    0.897    0.091    0.071   -0.387   -0.965    -0.958     0.098     0.683     0.142     0.172    -0.847     0.340     0.200     0.935     0.251     0.112    -0.324    -0.945    -0.960    -0.913    -0.856     0.800    -0.963    -0.883    -0.966    -0.958    -0.944    -0.376    -0.849    -0.916    -0.964    -0.641    -0.685     0.470     0.339    -0.267     0.138     0.000     0.000     0.000     0.000     0.000         -0.255\n  25_January_2024    0.062   -0.664    0.747    0.092   -0.002   -0.962   -0.194    0.705    0.271     0.123    -0.903     0.811     0.145    -0.631    -0.963     0.872     0.711     0.500    -0.864    -0.860    -0.948    -0.902    -0.820    -0.695    -0.895    -0.773    -0.240     0.474     0.168     0.082     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.185\n    07_March_2024   -0.004   -0.952   -0.959    0.166    0.240    0.011   -0.965   -0.079    0.518     0.696     0.177    -0.830    -0.937    -0.912     0.899     0.152     0.039    -0.873    -0.929     0.674     0.849    -0.961    -0.933    -0.933    -0.932    -0.933    -0.915     0.255     0.881    -0.888     0.548     0.172     0.072     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.230\n    11_April_2024    0.042   -0.711    0.739    0.843    0.015   -0.963   -0.525    0.090    0.723     0.114     0.223    -0.577     0.825     0.744     0.033    -0.835    -0.823    -0.653     0.876    -0.802    -0.964    -0.839    -0.938    -0.798    -0.906    -0.821    -0.965    -0.954     0.147     0.584     0.573     0.114     0.092     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.191\n     06_June_2024   -0.121    0.288    0.626   -0.298    0.698    0.069   -0.544   -0.486   -0.963    -0.387     0.392     0.798     0.169    -0.079    -0.150     0.378     0.132     0.225    -0.075    -0.004     0.938    -0.693    -0.853     0.889     0.205    -0.099     0.727    -0.939    -0.775    -0.936    -0.852    -0.692    -0.924    -0.695     0.201     0.391     0.137     0.103     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.084\n     18_July_2024    0.026   -0.471    0.418    0.026   -0.963   -0.964    0.116    0.668    0.159     0.148    -0.797     0.499     0.014     0.323    -0.046    -0.318     0.900     0.850     0.873    -0.396     0.767    -0.490    -0.895    -0.916    -0.929    -0.846    -0.680    -0.959    -0.802     0.907     0.062     0.113     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.113\n12_September_2024   -0.250   -0.031   -0.821   -0.806   -0.876    0.037    0.040    0.014   -0.251    -0.566    -0.964    -0.135     0.658     0.773     0.176    -0.348     0.429    -0.691    -0.342    -0.154     0.149     0.026     0.012    -0.911    -0.828    -0.812     0.528    -0.961    -0.944    -0.907    -0.956    -0.777    -0.932    -0.938    -0.305    -0.894    -0.959    -0.957    -0.671     0.163     0.103     0.000     0.000     0.000     0.000     0.000         -0.387\n  17_October_2024   -0.183   -0.485   -0.627    0.399    0.030   -0.947   -0.965    0.088    0.498     0.170     0.679    -0.173    -0.838     0.781     0.046    -0.918    -0.958    -0.753     0.925     0.782    -0.328    -0.956    -0.718    -0.889    -0.956    -0.505    -0.875    -0.928    -0.948    -0.343    -0.082     0.166     0.079     0.120     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.283\n 12_December_2024   -0.187   -0.154   -0.707   -0.619   -0.750    0.726    0.031   -0.600   -0.966     0.642     0.745     0.200     0.013     0.133    -0.021    -0.893     0.651     0.230     0.310    -0.963    -0.960     0.220     0.883     0.683     0.667    -0.658     0.780     0.916    -0.866    -0.947    -0.566    -0.806    -0.948    -0.962    -0.878     0.941     0.270     0.052     0.067     0.170     0.000     0.000     0.000     0.000     0.000     0.000         -0.103\n  30_January_2025   -0.171    0.567    0.621   -0.391    0.494    0.024   -0.574   -0.960    0.746     0.135    -0.208     0.894     0.881     0.521     0.404     0.021    -0.939     0.937     0.884     0.783     0.931     0.237     0.443     0.028    -0.952    -0.783    -0.884     0.824    -0.827    -0.472    -0.897    -0.641     0.061     0.150     0.180     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000          0.059\n    06_March_2025   -0.238    0.505    0.174    0.652   -0.952   -0.269    0.227    0.005    0.349    -0.748    -0.601     0.815    -0.390    -0.177     0.115    -0.151    -0.849    -0.928    -0.722    -0.939     0.125    -0.730    -0.949     0.202    -0.178     0.229     0.098     0.032     0.044    -0.037     0.222     0.044     0.021     0.002     0.049     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.141\n    17_April_2025   -0.286   -0.883    0.839   -0.919    0.104   -0.310   -0.961    0.767    0.202    -0.273    -0.759    -0.923    -0.775     0.085    -0.831    -0.311    -0.733     0.886     0.733    -0.957    -0.854    -0.943    -0.955    -0.955    -0.917    -0.919    -0.940    -0.882    -0.938    -0.203    -0.784    -0.382     0.223     0.238     0.183     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.410\n     05_June_2025   -0.207   -0.161   -0.495   -0.383    0.821   -0.702    0.747    0.867    0.012    -0.443    -0.953     0.172     0.029    -0.429    -0.316    -0.813     0.907    -0.637     0.474     0.915     0.009    -0.951    -0.930     0.896     0.898     0.509    -0.939    -0.530    -0.880    -0.673    -0.945    -0.464     0.047    -0.123    -0.528    -0.894     0.915     0.755    -0.068     0.194     0.235     0.085     0.000     0.000     0.000     0.000         -0.095\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"#finbert single\nfrom transformers import pipeline\nimport os\nimport pandas as pd\nfrom datetime import datetime\n\n# OPTION: Ausgabe ein/ausschalten\nSHOW_PROGRESS = True  # Setze auf True für Fortschrittsanzeige\n\n# Model laden\nsentiment_analyzer = pipeline(\"text-classification\", model=\"ProsusAI/finbert\", top_k=None)\n\n# Pfad zu den Ordnern\ninput_folder = \"/kaggle/input/llm-text/TEXT/EZB\"\n\n# Alle Datums-Ordner durchgehen\ndate_folders = sorted([f for f in os.listdir(input_folder) if os.path.isdir(os.path.join(input_folder, f))])\n\nresults = []\n\nfor date_folder in date_folders:\n    conclusion_file = os.path.join(input_folder, date_folder, \"0_FULL.txt\")\n    \n    if os.path.exists(conclusion_file):\n        if SHOW_PROGRESS:\n            print(f\"Verarbeite: {date_folder}\")\n        \n        # Datei lesen\n        with open(conclusion_file, 'r', encoding='utf-8') as file:\n            text = file.read()\n        \n        # Text in Chunks aufteilen\n        chunks = [text[i:i+512] for i in range(0, len(text), 400) if len(text[i:i+512].strip()) > 50]\n        \n        # Chunks analysieren\n        optimism_scores = []\n        for chunk in chunks:\n            result = sentiment_analyzer(chunk)\n            \n            neg_prob = next(r['score'] for r in result[0] if r['label'] == 'negative')\n            pos_prob = next(r['score'] for r in result[0] if r['label'] == 'positive')\n            \n            optimism_score = pos_prob - neg_prob\n            \n            # ✅ NUR WERTE AUßERHALB des neutralen Bereichs (-0.005 bis +0.005) hinzufügen\n            if optimism_score < -0.005 or optimism_score > 0.005:\n                optimism_scores.append(optimism_score)\n        \n        # Gesamtergebnis - nur mit gefilterten Werten\n        if optimism_scores:  # Prüfe ob noch Werte übrig sind\n            overall_optimism = sum(optimism_scores) / len(optimism_scores)\n        else:\n            overall_optimism = 0  # Fallback wenn alle Werte neutral waren\n        \n        # Zeile für DataFrame vorbereiten - KORREKTE REIHENFOLGE\n        row = {'Date': date_folder}\n        for idx, score in enumerate(optimism_scores, 1):\n            row[f'Chunk_{idx}'] = round(score, 3)\n        row['Overall_Score'] = round(overall_optimism, 3)\n        row['Valid_Chunks'] = len(optimism_scores)  # ✅ Anzahl verwendeter Chunks\n        results.append(row)\n\n# DataFrame erstellen\ndf = pd.DataFrame(results).fillna(0)\n\n# Spalten in korrekter Reihenfolge sortieren\nchunk_cols = [col for col in df.columns if col.startswith('Chunk_')]\nchunk_cols = sorted(chunk_cols, key=lambda x: int(x.split('_')[1]))\ncolumn_order = ['Date'] + chunk_cols + ['Overall_Score', 'Valid_Chunks']\ndf = df[column_order]\n\n# Zeitliche Sortierung\ndef parse_date(date_str):\n    try:\n        parts = date_str.split('_')\n        if len(parts) == 3:\n            day, month, year = parts\n            return datetime.strptime(f\"{day} {month} {year}\", \"%d %B %Y\")\n        else:\n            return datetime.max\n    except:\n        return datetime.max\n\ndf['Parsed_Date'] = df['Date'].apply(parse_date)\ndf_sorted = df.sort_values('Parsed_Date').drop(columns=['Parsed_Date'])\n\n# Direkte Ausgabe\nprint(df_sorted.to_string(index=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:40:17.240183Z","iopub.execute_input":"2025-07-02T20:40:17.240446Z","iopub.status.idle":"2025-07-02T20:40:27.661529Z","shell.execute_reply.started":"2025-07-02T20:40:17.240429Z","shell.execute_reply":"2025-07-02T20:40:27.660796Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Verarbeite: 02_February_2023\nVerarbeite: 04_May_2023\nVerarbeite: 05_June_2025\nVerarbeite: 06_June_2024\nVerarbeite: 06_March_2025\nVerarbeite: 07_March_2024\nVerarbeite: 08_September_2022\nVerarbeite: 09_June_2022\nVerarbeite: 11_April_2024\nVerarbeite: 12_December_2024\nVerarbeite: 12_September_2024\nVerarbeite: 14_December_2023\nVerarbeite: 14_September_2023\nVerarbeite: 15_December_2022\nVerarbeite: 15_June_2023\nVerarbeite: 16_March_2023\nVerarbeite: 17_April_2025\nVerarbeite: 17_October_2024\nVerarbeite: 18_July_2024\nVerarbeite: 21_July_2022\nVerarbeite: 25_January_2024\nVerarbeite: 26_October_2023\nVerarbeite: 27_July_2023\nVerarbeite: 27_October_2022\nVerarbeite: 30_January_2025\n             Date  Chunk_1  Chunk_2  Chunk_3  Chunk_4  Chunk_5  Chunk_6  Chunk_7  Chunk_8  Chunk_9  Chunk_10  Chunk_11  Chunk_12  Chunk_13  Chunk_14  Chunk_15  Chunk_16  Chunk_17  Chunk_18  Chunk_19  Chunk_20  Chunk_21  Chunk_22  Chunk_23  Chunk_24  Chunk_25  Chunk_26  Chunk_27  Chunk_28  Chunk_29  Chunk_30  Chunk_31  Chunk_32  Chunk_33  Chunk_34  Chunk_35  Chunk_36  Chunk_37  Chunk_38  Chunk_39  Chunk_40  Chunk_41  Chunk_42  Chunk_43  Chunk_44  Chunk_45  Overall_Score  Valid_Chunks\n     09_June_2022    0.028    0.754   -0.919   -0.943   -0.435   -0.920   -0.025    0.476   -0.155     0.062     0.602     0.053     0.624     0.099     0.163     0.895     0.054     0.753     0.749    -0.936    -0.855    -0.880     0.908    -0.051     0.091     0.797     0.275     0.301     0.065    -0.942     0.636     0.874     0.865     0.923     0.916     0.884    -0.894    -0.890     0.880     0.937    -0.936     0.331    -0.739     0.674     0.314          0.121            45\n     21_July_2022    0.066    0.839    0.754    0.319    0.365    0.399    0.174    0.328    0.615     0.733     0.486     0.497     0.310     0.526     0.628     0.867     0.821     0.751     0.544     0.222     0.186     0.084    -0.960     0.898     0.903     0.900     0.556    -0.657     0.504     0.647    -0.918    -0.935    -0.825    -0.612    -0.927    -0.938     0.506     0.796     0.114     0.000     0.000     0.000     0.000     0.000     0.000          0.245            39\n08_September_2022    0.195    0.890    0.661   -0.877   -0.667   -0.950   -0.932    0.362    0.775    -0.040     0.178     0.168     0.451     0.797     0.314     0.878     0.769    -0.092    -0.853    -0.953    -0.949    -0.248     0.057     0.932    -0.916    -0.959    -0.538     0.905     0.925     0.701    -0.288     0.548    -0.414    -0.939    -0.926     0.380    -0.632     0.881     0.167     0.000     0.000     0.000     0.000     0.000     0.000         -0.006            39\n  27_October_2022    0.367    0.779   -0.145    0.591    0.179    0.033    0.089    0.446    0.115     0.329     0.014     0.600     0.122     0.825     0.758    -0.589     0.325     0.258     0.021    -0.908    -0.963    -0.964    -0.897    -0.448     0.866     0.934     0.808     0.846     0.823    -0.942    -0.845    -0.626    -0.920     0.462     0.913     0.214     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000          0.096            36\n 15_December_2022    0.403    0.856    0.038   -0.963   -0.469    0.688   -0.910   -0.893   -0.948    -0.870     0.699    -0.962    -0.323     0.583     0.677     0.197     0.848     0.825    -0.961    -0.896     0.046    -0.899    -0.920    -0.958    -0.965    -0.093    -0.961    -0.843    -0.445     0.682     0.694    -0.817     0.138     0.934     0.929    -0.931    -0.813     0.330    -0.941    -0.859     0.605     0.899    -0.925    -0.357     0.068         -0.195            45\n 02_February_2023    0.136    0.787    0.424   -0.961    0.027    0.291    0.637   -0.940   -0.907     0.249     0.252     0.336     0.505     0.666     0.800     0.258    -0.917     0.189     0.127    -0.878    -0.950     0.883    -0.877     0.268     0.821     0.672    -0.912     0.792    -0.733     0.901     0.383    -0.495     0.803     0.680    -0.804    -0.955    -0.962    -0.449     0.788    -0.952     0.132     0.000     0.000     0.000     0.000          0.003            41\n    16_March_2023    0.106    0.718    0.727    0.075   -0.934   -0.856    0.265    0.764   -0.964     0.145     0.486     0.680     0.205     0.351     0.843     0.853    -0.006    -0.920    -0.813     0.859    -0.794    -0.941     0.932     0.736     0.609     0.818    -0.947     0.866     0.850    -0.680    -0.949    -0.606     0.418    -0.858    -0.760    -0.948     0.236     0.314     0.271     0.000     0.000     0.000     0.000     0.000     0.000          0.030            39\n      04_May_2023   -0.033    0.519    0.212    0.130   -0.065    0.661   -0.966    0.419    0.709     0.167     0.192     0.643     0.253     0.109    -0.049     0.929    -0.939     0.352     0.716     0.440    -0.819    -0.957     0.506     0.880    -0.848     0.714    -0.761    -0.923     0.931    -0.948    -0.389     0.617     0.247     0.419     0.096     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000          0.090            35\n     15_June_2023   -0.064    0.408   -0.486   -0.848   -0.339    0.139    0.077   -0.943   -0.959     0.166     0.514     0.791     0.172     0.610     0.432    -0.945    -0.887     0.178    -0.102    -0.895    -0.956    -0.773     0.914    -0.902    -0.949    -0.908     0.812    -0.945    -0.942     0.161    -0.860    -0.253    -0.942    -0.961    -0.919    -0.667     0.650     0.239     0.222     0.178     0.000     0.000     0.000     0.000     0.000         -0.270            40\n     27_July_2023    0.672   -0.039    0.277    0.120    0.269    0.518   -0.961    0.151    0.185     0.766     0.221     0.713     0.892     0.712     0.253     0.693     0.113    -0.963    -0.894    -0.543     0.815    -0.888    -0.929     0.482    -0.770    -0.947    -0.574    -0.404     0.337     0.930    -0.879    -0.968    -0.962     0.532     0.246     0.167     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.018            36\n14_September_2023    0.009    0.890   -0.480   -0.935   -0.849    0.612    0.055    0.791   -0.964     0.384     0.707     0.338     0.117     0.896    -0.348    -0.788    -0.932     0.843     0.038    -0.950    -0.588    -0.861     0.797     0.861    -0.947    -0.959    -0.793    -0.961    -0.708     0.659     0.360    -0.516    -0.959    -0.961     0.896     0.406     0.163     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.126            37\n  26_October_2023    0.486   -0.697    0.854    0.116    0.019   -0.963   -0.758   -0.757    0.558     0.842    -0.963    -0.929    -0.963    -0.936    -0.933     0.525     0.420     0.544     0.928    -0.949    -0.964    -0.959    -0.615     0.846     0.146     0.044     0.037    -0.087    -0.043     0.235     0.185    -0.104     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.151            32\n 14_December_2023   -0.824    0.514    0.673    0.897    0.091    0.071   -0.387   -0.965   -0.958     0.098     0.683     0.142     0.172    -0.847     0.340     0.200     0.935     0.251     0.112    -0.324    -0.945    -0.960    -0.913    -0.856     0.800    -0.963    -0.883    -0.966    -0.958    -0.944    -0.376    -0.849    -0.916    -0.964    -0.641    -0.685     0.470     0.339    -0.267     0.138     0.000     0.000     0.000     0.000     0.000         -0.262            40\n  25_January_2024    0.062   -0.664    0.747    0.092   -0.962   -0.194    0.705    0.271    0.123    -0.903     0.811     0.145    -0.631    -0.963     0.872     0.711     0.500    -0.864    -0.860    -0.948    -0.902    -0.820    -0.695    -0.895    -0.773    -0.240     0.474     0.168     0.082     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.191            29\n    07_March_2024   -0.952   -0.959    0.166    0.240    0.011   -0.965   -0.079    0.518    0.696     0.177    -0.830    -0.937    -0.912     0.899     0.152     0.039    -0.873    -0.929     0.674     0.849    -0.961    -0.933    -0.933    -0.932    -0.933    -0.915     0.255     0.881    -0.888     0.548     0.172     0.072     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.237            32\n    11_April_2024    0.042   -0.711    0.739    0.843    0.015   -0.963   -0.525    0.090    0.723     0.114     0.223    -0.577     0.825     0.744     0.033    -0.835    -0.823    -0.653     0.876    -0.802    -0.964    -0.839    -0.938    -0.798    -0.906    -0.821    -0.965    -0.954     0.147     0.584     0.573     0.114     0.092     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.191            33\n     06_June_2024   -0.121    0.288    0.626   -0.298    0.698    0.069   -0.544   -0.486   -0.963    -0.387     0.392     0.798     0.169    -0.079    -0.150     0.378     0.132     0.225    -0.075     0.938    -0.693    -0.853     0.889     0.205    -0.099     0.727    -0.939    -0.775    -0.936    -0.852    -0.692    -0.924    -0.695     0.201     0.391     0.137     0.103     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.086            37\n     18_July_2024    0.026   -0.471    0.418    0.026   -0.963   -0.964    0.116    0.668    0.159     0.148    -0.797     0.499     0.014     0.323    -0.046    -0.318     0.900     0.850     0.873    -0.396     0.767    -0.490    -0.895    -0.916    -0.929    -0.846    -0.680    -0.959    -0.802     0.907     0.062     0.113     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.113            32\n12_September_2024   -0.250   -0.031   -0.821   -0.806   -0.876    0.037    0.040    0.014   -0.251    -0.566    -0.964    -0.135     0.658     0.773     0.176    -0.348     0.429    -0.691    -0.342    -0.154     0.149     0.026     0.012    -0.911    -0.828    -0.812     0.528    -0.961    -0.944    -0.907    -0.956    -0.777    -0.932    -0.938    -0.305    -0.894    -0.959    -0.957    -0.671     0.163     0.103     0.000     0.000     0.000     0.000         -0.387            41\n  17_October_2024   -0.183   -0.485   -0.627    0.399    0.030   -0.947   -0.965    0.088    0.498     0.170     0.679    -0.173    -0.838     0.781     0.046    -0.918    -0.958    -0.753     0.925     0.782    -0.328    -0.956    -0.718    -0.889    -0.956    -0.505    -0.875    -0.928    -0.948    -0.343    -0.082     0.166     0.079     0.120     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.283            34\n 12_December_2024   -0.187   -0.154   -0.707   -0.619   -0.750    0.726    0.031   -0.600   -0.966     0.642     0.745     0.200     0.013     0.133    -0.021    -0.893     0.651     0.230     0.310    -0.963    -0.960     0.220     0.883     0.683     0.667    -0.658     0.780     0.916    -0.866    -0.947    -0.566    -0.806    -0.948    -0.962    -0.878     0.941     0.270     0.052     0.067     0.170     0.000     0.000     0.000     0.000     0.000         -0.103            40\n  30_January_2025   -0.171    0.567    0.621   -0.391    0.494    0.024   -0.574   -0.960    0.746     0.135    -0.208     0.894     0.881     0.521     0.404     0.021    -0.939     0.937     0.884     0.783     0.931     0.237     0.443     0.028    -0.952    -0.783    -0.884     0.824    -0.827    -0.472    -0.897    -0.641     0.061     0.150     0.180     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000          0.059            35\n    06_March_2025   -0.238    0.505    0.174    0.652   -0.952   -0.269    0.227    0.005    0.349    -0.748    -0.601     0.815    -0.390    -0.177     0.115    -0.151    -0.849    -0.928    -0.722    -0.939     0.125    -0.730    -0.949     0.202    -0.178     0.229     0.098     0.032     0.044    -0.037     0.222     0.044     0.021     0.049     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.146            34\n    17_April_2025   -0.286   -0.883    0.839   -0.919    0.104   -0.310   -0.961    0.767    0.202    -0.273    -0.759    -0.923    -0.775     0.085    -0.831    -0.311    -0.733     0.886     0.733    -0.957    -0.854    -0.943    -0.955    -0.955    -0.917    -0.919    -0.940    -0.882    -0.938    -0.203    -0.784    -0.382     0.223     0.238     0.183     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.410            35\n     05_June_2025   -0.207   -0.161   -0.495   -0.383    0.821   -0.702    0.747    0.867    0.012    -0.443    -0.953     0.172     0.029    -0.429    -0.316    -0.813     0.907    -0.637     0.474     0.915     0.009    -0.951    -0.930     0.896     0.898     0.509    -0.939    -0.530    -0.880    -0.673    -0.945    -0.464     0.047    -0.123    -0.528    -0.894     0.915     0.755    -0.068     0.194     0.235     0.085     0.000     0.000     0.000         -0.095            42\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#fin-roberta single\n\nfrom transformers import pipeline\nimport os\nimport pandas as pd\nfrom datetime import datetime\n\n# OPTION: Ausgabe ein/ausschalten\nSHOW_PROGRESS = True\n\n# Model laden\nsentiment_analyzer = pipeline(\"text-classification\", model=\"soleimanian/financial-roberta-large-sentiment\", top_k=None)\n\n# Pfad zu den Ordnern\ninput_folder = \"/kaggle/input/llm-text/TEXT/EZB/\"\n\n# Alle Datums-Ordner durchgehen\ndate_folders = [f for f in os.listdir(input_folder) if os.path.isdir(os.path.join(input_folder, f))]\n\nresults = []\n\nfor date_folder in date_folders:\n    conclusion_file = os.path.join(input_folder, date_folder, \"0_FULL.txt\")\n    \n    if os.path.exists(conclusion_file):\n        if SHOW_PROGRESS:\n            print(f\"Verarbeite: {date_folder}\")\n        \n        # Datei lesen\n        with open(conclusion_file, 'r', encoding='utf-8') as file:\n            text = file.read()\n        \n        # Text in Chunks aufteilen\n        chunks = [text[i:i+512] for i in range(0, len(text), 400) if len(text[i:i+512].strip()) > 50]\n        \n        # Chunks analysieren\n        optimism_scores = []\n        for chunk in chunks:\n            result = sentiment_analyzer(chunk)\n            \n            # KORREKTUR: result[0] verwenden!\n            labels = {r['label']: r['score'] for r in result[0]}\n            \n            neg_prob = labels.get('negative', 0)\n            pos_prob = labels.get('positive', 0)\n            \n            optimism_score = pos_prob - neg_prob\n            optimism_scores.append(optimism_score)\n        \n        # Gesamtergebnis\n        overall_optimism = sum(optimism_scores) / len(optimism_scores)\n        \n        # Zeile für DataFrame vorbereiten\n        row = {'Date': date_folder}\n        for idx, score in enumerate(optimism_scores, 1):\n            row[f'Chunk_{idx}'] = round(score, 3)\n        row['Overall_Score'] = round(overall_optimism, 3)\n        results.append(row)\n\n# DataFrame erstellen\ndf = pd.DataFrame(results).fillna(0)\n\n# CHRONOLOGISCHE SORTIERUNG\ndef parse_date(date_str):\n    try:\n        parts = date_str.split('_')\n        if len(parts) == 3:\n            day, month, year = parts\n            return datetime.strptime(f\"{day} {month} {year}\", \"%d %B %Y\")\n        else:\n            return datetime.max\n    except:\n        return datetime.max\n\ndf['Parsed_Date'] = df['Date'].apply(parse_date)\ndf_sorted = df.sort_values('Parsed_Date').drop(columns=['Parsed_Date'])\n\n# Spalten in korrekter Reihenfolge sortieren\nchunk_cols = [col for col in df_sorted.columns if col.startswith('Chunk_')]\nchunk_cols = sorted(chunk_cols, key=lambda x: int(x.split('_')[1]))\ncolumn_order = ['Date'] + chunk_cols + ['Overall_Score']\ndf_final = df_sorted[column_order]\n\nprint(df_final.to_string(index=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:40:27.662302Z","iopub.execute_input":"2025-07-02T20:40:27.662571Z","iopub.status.idle":"2025-07-02T20:41:03.510396Z","shell.execute_reply.started":"2025-07-02T20:40:27.662534Z","shell.execute_reply":"2025-07-02T20:41:03.509672Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Verarbeite: 17_October_2024\nVerarbeite: 17_April_2025\nVerarbeite: 14_December_2023\nVerarbeite: 11_April_2024\nVerarbeite: 12_December_2024\nVerarbeite: 21_July_2022\nVerarbeite: 08_September_2022\nVerarbeite: 14_September_2023\nVerarbeite: 12_September_2024\nVerarbeite: 07_March_2024\nVerarbeite: 27_October_2022\nVerarbeite: 16_March_2023\nVerarbeite: 06_March_2025\nVerarbeite: 26_October_2023\nVerarbeite: 27_July_2023\nVerarbeite: 25_January_2024\nVerarbeite: 02_February_2023\nVerarbeite: 30_January_2025\nVerarbeite: 18_July_2024\nVerarbeite: 05_June_2025\nVerarbeite: 09_June_2022\nVerarbeite: 15_December_2022\nVerarbeite: 15_June_2023\nVerarbeite: 04_May_2023\nVerarbeite: 06_June_2024\n             Date  Chunk_1  Chunk_2  Chunk_3  Chunk_4  Chunk_5  Chunk_6  Chunk_7  Chunk_8  Chunk_9  Chunk_10  Chunk_11  Chunk_12  Chunk_13  Chunk_14  Chunk_15  Chunk_16  Chunk_17  Chunk_18  Chunk_19  Chunk_20  Chunk_21  Chunk_22  Chunk_23  Chunk_24  Chunk_25  Chunk_26  Chunk_27  Chunk_28  Chunk_29  Chunk_30  Chunk_31  Chunk_32  Chunk_33  Chunk_34  Chunk_35  Chunk_36  Chunk_37  Chunk_38  Chunk_39  Chunk_40  Chunk_41  Chunk_42  Chunk_43  Chunk_44  Chunk_45  Chunk_46  Overall_Score\n     09_June_2022    0.002   -0.998   -0.973   -0.993   -0.998    0.980    0.267    0.016    0.002     0.001     0.573     0.997     0.973     0.000     0.009     0.062     0.996     0.001     0.001    -0.998    -0.979     0.277    -0.998     0.997    -0.973     0.048     0.997     0.993     0.000     0.000    -0.999     0.759     0.997    -0.920    -0.983     0.974     0.997    -0.968    -0.998    -0.997     0.997    -0.998    -0.998     0.003    -0.981     0.672         -0.069\n     21_July_2022    0.002    0.997    0.997    0.573    0.003    0.051    0.700    0.995    0.683     0.005     0.991     0.553     0.996     0.995     0.001     0.997     0.997     0.310     0.008     0.002     0.067     0.013    -0.999     0.034     0.997    -0.086    -0.998    -0.999     0.976     0.997     0.990    -0.998    -0.998    -0.998    -0.998     0.546     0.033     0.550     0.005     0.000     0.000     0.000     0.000     0.000     0.000     0.000          0.231\n08_September_2022    0.942    0.093    0.227   -0.998   -0.970   -0.999   -0.998    0.968    0.996     0.980     0.232     0.742     0.991     0.996     0.864     0.996     0.995    -0.998    -0.998    -0.999    -0.999    -0.944     0.017     0.997    -0.998    -0.999    -0.997    -0.999    -0.982    -0.996    -0.998     0.395    -0.972    -0.998    -0.997    -0.995    -0.998    -0.997     0.857     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.245\n  27_October_2022    0.981    0.997   -0.998   -0.995    0.000    0.891    0.022    0.953    0.048     0.988     0.008     0.993     0.994     0.997     0.953    -0.999     0.001     0.000     0.008    -0.995    -0.999    -0.999    -0.998    -0.004     0.951     0.964    -0.998    -0.998     0.995    -0.998    -0.996    -0.998    -0.997     0.022     0.997     0.058     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.004\n 15_December_2022    0.991   -0.937    0.038   -0.007    0.000    0.452   -0.997   -0.996   -0.998    -0.985     0.995    -0.000     0.001     0.996     0.984     0.993     0.843    -0.000     0.000    -0.000     0.025     0.471    -0.994     0.037    -0.998    -0.464    -0.999    -0.998     0.965    -0.001     0.005    -0.982    -0.997    -0.446     0.996    -0.995    -0.995    -0.139    -0.998    -0.998    -0.175     0.008     0.989     0.002     0.016     0.000         -0.140\n 02_February_2023    0.001    0.987    0.034    0.000    0.000    0.997    0.980    0.989    0.000     0.973     0.196     0.997     0.000     0.071     0.996     0.494    -0.000     0.029     0.990    -0.998    -0.999     0.992     0.996    -0.073    -0.003     0.190     0.920    -0.998    -0.998    -0.998    -0.984    -0.998     0.207     0.004    -0.988    -0.999    -0.998    -0.996     0.995     0.801     0.003     0.000     0.000     0.000     0.000     0.000          0.069\n    16_March_2023   -0.110    0.373    0.994    0.742   -0.998   -0.998    0.954   -0.998   -0.093     0.002     0.995     0.995     0.995    -0.001     0.993     0.997    -0.110    -0.998    -0.994     0.997    -0.998    -0.998     0.997     0.996     0.001     0.013     0.701    -0.998    -0.998     0.993    -0.999    -0.916    -0.998    -0.997    -0.995    -0.999    -0.997     0.001     0.603     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.073\n      04_May_2023   -0.855   -0.950   -0.997    0.002    0.000    0.317   -0.998    0.004    0.988     0.995     0.973    -0.001     0.241    -0.993     0.001     0.001     0.978    -0.998     0.984    -0.048     0.020    -0.531    -0.997    -0.998    -0.996    -0.998     0.811    -0.995    -0.998    -0.224    -0.998    -0.998    -0.004     0.004     0.003     0.015     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.229\n     15_June_2023   -0.994    0.996   -0.717   -0.996   -0.998    0.075    0.037    0.995   -0.991     0.779     0.926     0.996     0.724    -0.992     0.991    -0.995    -0.999    -0.997     0.003    -0.998    -0.999    -0.966     0.001     0.995     0.995    -0.153    -0.996    -0.998    -0.997     0.004    -0.989    -0.981    -0.998    -0.998    -0.998    -0.992     0.994     0.989     0.002     0.636     0.000     0.000     0.000     0.000     0.000     0.000         -0.240\n     27_July_2023   -0.996    0.995   -0.979   -0.912    0.001    0.997    0.690    0.444    0.455     0.575     0.993     0.637    -0.895     0.955    -0.993     0.002     0.997     0.947    -0.999    -0.998     0.995     0.003     0.997     0.993    -0.986    -0.998    -0.998    -0.482    -0.992     0.267    -0.978    -0.886    -0.998    -0.998    -0.995     0.002     0.984     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.085\n14_September_2023   -0.993    0.994    0.948   -0.998   -0.998    0.983    0.001    0.996   -0.003     0.993     0.380     0.995    -0.993    -0.992     0.995    -0.998    -0.998     0.997     0.003    -0.998    -0.998     0.515    -0.992     0.852     0.122     0.996    -0.992    -0.997    -0.958    -0.994    -0.987    -0.980    -0.998    -0.999    -0.389     0.996     0.008     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.175\n  26_October_2023    0.000   -0.986    0.727    0.990    0.000   -0.999   -0.998    0.932   -0.972     0.002     0.996     0.989     0.996     0.883    -0.996    -0.993    -0.997    -0.997    -0.998    -0.995    -0.998    -0.998    -0.998     0.982     0.487     0.003    -0.538    -0.006    -0.047    -0.838    -0.001     0.885     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.161\n 14_December_2023    0.000   -0.980   -0.994   -0.997    0.997    0.952    0.002    0.672   -0.581    -0.967     0.023     0.782     0.995    -0.000    -0.952    -0.997    -0.998     0.997     0.995     0.004     0.592    -0.998    -0.999    -0.998    -0.159     0.002     0.985    -0.993     0.997    -0.751    -0.998    -0.573    -0.983    -0.433    -0.998    -0.995    -0.997     0.093     0.997     0.028     0.921     0.000     0.000     0.000     0.000     0.000         -0.178\n  25_January_2024    0.001   -0.997   -0.974    0.003    0.000   -0.980    0.111    0.141    0.997     0.012    -0.997    -0.962     0.985    -0.998    -0.991    -0.949     0.794    -0.001     0.995     0.990     0.367    -0.993    -0.165    -0.487    -0.994    -0.995    -0.998     0.987     0.744     0.001     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.178\n    07_March_2024    0.000   -0.995   -0.998   -0.997    0.985    0.000    0.001    0.006    0.994     0.987     0.987    -0.997    -0.995    -0.998     0.023     0.064     0.000    -0.993     0.997    -0.047     0.797     0.996     0.988     0.547     0.927    -0.996    -0.838    -0.995    -0.995    -0.998     0.990     0.674     0.001     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.027\n    11_April_2024    0.001    0.992   -0.997   -0.329    0.411   -0.001   -0.586    0.062    0.964     0.993     0.000     0.995    -0.946     0.004     0.001    -0.997     0.997     0.994     0.350     0.996     0.994    -0.995    -0.991    -0.995    -0.995    -0.994     0.025    -0.995    -0.993     0.172     0.006     0.002     0.004     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.056\n     06_June_2024    0.000    0.996    0.996   -0.998    0.965    0.001    0.001    0.994   -0.991     0.583     0.945     0.996     0.915    -0.536     0.996    -0.992     0.995    -0.286     0.000     0.000     0.997     0.997     0.996     0.996    -0.972    -0.500    -0.333     0.995    -0.990    -0.997    -0.726    -0.998    -0.998    -0.534     0.021     0.996     0.004     0.002     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000          0.119\n     18_July_2024    0.001    0.012   -0.996    0.000   -0.002   -0.998    0.223    0.911    0.992     0.000     0.019    -0.996     0.000    -0.989     0.141     0.997     0.921     0.988     0.996    -0.987    -0.998    -0.997    -0.980    -0.994    -0.635    -0.994    -0.994    -0.996    -0.998    -0.817     0.001     0.003     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.255\n12_September_2024   -0.000    0.993   -0.002    0.114   -0.998   -0.996    0.000    0.000   -0.000     0.535    -0.982    -0.897     0.725     0.996     0.590     0.985    -0.068     0.321    -0.989    -0.998     0.004     0.000     0.000    -0.998    -0.921     0.453     0.076     0.993     0.988    -0.998     0.996     0.996     0.738    -0.998    -0.177    -0.995     0.039    -0.998    -0.802     0.002     0.002     0.000     0.000     0.000     0.000     0.000         -0.055\n  17_October_2024   -0.001    0.838   -0.992    0.996    0.000    0.741   -0.998    0.038    0.931     0.993     0.000     0.090    -0.944    -0.813     0.002    -0.997    -0.999    -0.994     0.997     0.033     0.997     0.996    -0.998     0.313    -0.998    -0.989    -0.992    -0.970    -0.107    -0.997     0.995     0.142     0.002     0.004     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.108\n 12_December_2024    0.000    0.846   -0.988   -0.997   -0.998    0.997    0.000    0.977   -0.998    -0.081     0.997     0.789     0.323     0.994     0.786    -0.998     0.047     0.971     0.011    -0.383    -0.996    -0.768     0.980     0.994     0.987    -0.511     0.991     0.990     0.993    -0.998    -0.994    -0.998    -0.998     0.997     0.997     0.997    -0.048     0.388     0.001     0.012     0.000     0.000     0.000     0.000     0.000     0.000          0.133\n  30_January_2025   -0.002    0.966    0.970   -0.994   -0.090    0.000    0.973   -0.963    0.692     0.937    -0.066     0.930     0.811    -0.053     0.993     0.000    -0.999     0.992     0.994     0.244    -0.998    -0.998    -0.826     0.521    -0.998    -0.995    -0.998    -0.998     0.997    -0.738    -0.998    -0.991     0.063     0.000     0.938     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.020\n    06_March_2025   -0.469    0.986   -0.931    0.975   -0.998   -0.995    0.471    0.000   -0.950    -0.995    -0.997     0.965     0.132     0.947     0.971     0.996    -0.991    -0.998    -0.986    -0.998    -0.990    -0.529    -0.995     0.995    -0.996     0.007     0.000     0.414    -0.169    -0.000     0.995     0.988     0.006     0.948     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000         -0.091\n    17_April_2025   -0.042    0.869    0.996   -0.999   -0.000   -0.001    0.996    0.988    0.993    -0.106     0.997    -0.998    -0.998     0.000    -0.993    -0.998     0.997     0.996     0.982     0.896     0.993     0.995    -0.998    -0.999    -0.998    -0.998    -0.997    -0.996     0.987    -0.570    -0.703     0.973     0.017     0.001     0.970     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000     0.000          0.064\n     05_June_2025   -0.006   -0.404   -0.993   -0.962    0.998   -0.733   -0.015    0.997    0.000     0.966     0.008     0.996     0.000    -0.901    -0.994    -0.997     0.986    -0.004    -0.956     0.997     0.000     0.877    -0.997    -0.997     0.995     0.052     0.996    -0.993     0.988     0.036    -0.989    -0.998    -0.964    -0.998    -0.984     0.997     0.997    -0.052     0.995     0.197     0.002     0.048     0.000     0.000     0.000     0.000         -0.043\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"#nicht optimierte Sätze!!!!-financial-roberta\n\nfrom transformers import pipeline\nimport os\nimport pandas as pd\nfrom datetime import datetime\nimport re\n\n# OPTION: Ausgabe ein/ausschalten\nSHOW_PROGRESS = True\n\n# Model laden\nsentiment_analyzer = pipeline(\"text-classification\", model=\"soleimanian/financial-roberta-large-sentiment\", top_k=None)\n\n# Pfad zu den Ordnern\ninput_folder =\"/kaggle/input/llm-text/TEXT/EZB/\"\n\n# Alle Datums-Ordner durchgehen\ndate_folders = [f for f in os.listdir(input_folder) if os.path.isdir(os.path.join(input_folder, f))]\n\nresults = []\n\ndef simple_sentence_split(text):\n    # Einfacher Satz-Splitter ohne NLTK\n    sentences = re.split(r'[.!?]+', text)\n    # Bereinige und filtere leere Sätze\n    sentences = [s.strip() for s in sentences if len(s.strip()) > 20]\n    return sentences\n\nfor date_folder in date_folders:\n    full_file = os.path.join(input_folder, date_folder, \"0_FULL.txt\")\n    \n    if os.path.exists(full_file):\n        if SHOW_PROGRESS:\n            print(f\"Verarbeite: {date_folder}\")\n        \n        # Datei lesen\n        with open(full_file, 'r', encoding='utf-8') as file:\n            text = file.read()\n        \n        # Satz-basierte Analyse\n        sentences = simple_sentence_split(text)\n        optimism_scores_sentences = []\n        for sentence in sentences:\n            if len(sentence.strip()) > 10:\n                result = sentiment_analyzer(sentence)\n                labels = {r['label']: r['score'] for r in result[0]}\n                neg_prob = labels.get('negative', 0)\n                pos_prob = labels.get('positive', 0)\n                optimism_score = pos_prob - neg_prob\n                optimism_scores_sentences.append(optimism_score)\n        overall_optimism_sentences = sum(optimism_scores_sentences) / len(optimism_scores_sentences) if optimism_scores_sentences else 0\n        \n        # Chunk-basierte Analyse\n        chunks = [text[i:i+512] for i in range(0, len(text), 400) if len(text[i:i+512].strip()) > 50]\n        optimism_scores_chunks = []\n        for chunk in chunks:\n            result = sentiment_analyzer(chunk)\n            labels = {r['label']: r['score'] for r in result[0]}\n            neg_prob = labels.get('negative', 0)\n            pos_prob = labels.get('positive', 0)\n            optimism_score = pos_prob - neg_prob\n            optimism_scores_chunks.append(optimism_score)\n        overall_optimism_chunks = sum(optimism_scores_chunks) / len(optimism_scores_chunks) if optimism_scores_chunks else 0\n        \n        # Ergebnisse speichern\n        row = {\n            'Date': date_folder,\n            'Optimism_Score_Sentences': round(overall_optimism_sentences, 3),\n            'Sentence_Count': len(optimism_scores_sentences),\n            'Optimism_Score_Chunks': round(overall_optimism_chunks, 3),\n            'Chunk_Count': len(optimism_scores_chunks)\n        }\n        results.append(row)\n\n# DataFrame erstellen\ndf = pd.DataFrame(results)\n\n# CHRONOLOGISCHE SORTIERUNG\ndef parse_date(date_str):\n    try:\n        parts = date_str.split('_')\n        if len(parts) == 3:\n            day, month, year = parts\n            return datetime.strptime(f\"{day} {month} {year}\", \"%d %B %Y\")\n        else:\n            return datetime.max\n    except:\n        return datetime.max\n\ndf['Parsed_Date'] = df['Date'].apply(parse_date)\ndf_sorted = df.sort_values('Parsed_Date').drop(columns=['Parsed_Date'])\n\n# Excel speichern\nexcel_path = 'ezb_optimism_scores_compare_sentences_chunks_financial_roberta.xlsx'\ndf_sorted.to_excel(excel_path, index=False)\n\nprint(df_sorted.to_string(index=False))\nprint(f\"Ergebnisse wurden in '{excel_path}' gespeichert.\")\n\n# Einfacher Download-Link\nfrom IPython.display import FileLink\ndisplay(FileLink(excel_path))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:41:03.511902Z","iopub.execute_input":"2025-07-02T20:41:03.512126Z","iopub.status.idle":"2025-07-02T20:42:26.668822Z","shell.execute_reply.started":"2025-07-02T20:41:03.512109Z","shell.execute_reply":"2025-07-02T20:42:26.668009Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Verarbeite: 17_October_2024\nVerarbeite: 17_April_2025\nVerarbeite: 14_December_2023\nVerarbeite: 11_April_2024\nVerarbeite: 12_December_2024\nVerarbeite: 21_July_2022\nVerarbeite: 08_September_2022\nVerarbeite: 14_September_2023\nVerarbeite: 12_September_2024\nVerarbeite: 07_March_2024\nVerarbeite: 27_October_2022\nVerarbeite: 16_March_2023\nVerarbeite: 06_March_2025\nVerarbeite: 26_October_2023\nVerarbeite: 27_July_2023\nVerarbeite: 25_January_2024\nVerarbeite: 02_February_2023\nVerarbeite: 30_January_2025\nVerarbeite: 18_July_2024\nVerarbeite: 05_June_2025\nVerarbeite: 09_June_2022\nVerarbeite: 15_December_2022\nVerarbeite: 15_June_2023\nVerarbeite: 04_May_2023\nVerarbeite: 06_June_2024\n             Date  Optimism_Score_Sentences  Sentence_Count  Optimism_Score_Chunks  Chunk_Count\n     09_June_2022                     0.089             138                 -0.069           46\n     21_July_2022                     0.125             109                  0.231           39\n08_September_2022                    -0.166             111                 -0.245           39\n  27_October_2022                    -0.058             101                 -0.004           36\n 15_December_2022                    -0.083             139                 -0.140           45\n 02_February_2023                     0.036             111                  0.069           41\n    16_March_2023                    -0.072             120                 -0.073           39\n      04_May_2023                    -0.104             105                 -0.229           36\n     15_June_2023                    -0.148             126                 -0.240           40\n     27_July_2023                    -0.005             108                 -0.085           37\n14_September_2023                    -0.014             120                 -0.175           37\n  26_October_2023                    -0.115             124                 -0.161           34\n 14_December_2023                    -0.094             141                 -0.178           41\n  25_January_2024                    -0.090              86                 -0.178           30\n    07_March_2024                    -0.001             113                 -0.027           33\n    11_April_2024                     0.052             102                 -0.056           33\n     06_June_2024                     0.096             130                  0.119           38\n     18_July_2024                    -0.088             101                 -0.255           32\n12_September_2024                    -0.067             143                 -0.055           41\n  17_October_2024                    -0.093             107                 -0.108           34\n 12_December_2024                    -0.027             144                  0.133           40\n  30_January_2025                     0.047             106                 -0.020           35\n    06_March_2025                    -0.022             137                 -0.091           35\n    17_April_2025                     0.030             113                  0.064           35\n     05_June_2025                    -0.009             132                 -0.043           42\nErgebnisse wurden in 'ezb_optimism_scores_compare_sentences_chunks_financial_roberta.xlsx' gespeichert.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/ezb_optimism_scores_compare_sentences_chunks_financial_roberta.xlsx","text/html":"<a href='ezb_optimism_scores_compare_sentences_chunks_financial_roberta.xlsx' target='_blank'>ezb_optimism_scores_compare_sentences_chunks_financial_roberta.xlsx</a><br>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"#nicht optimierte Sätze!!!-finbert\n\nfrom transformers import pipeline\nimport os\nimport pandas as pd\nfrom datetime import datetime\nfrom IPython.display import FileLink\nimport re\n\n# OPTION: Ausgabe ein/ausschalten\nSHOW_PROGRESS = True\n\n# Model laden\nsentiment_analyzer = pipeline(\"text-classification\", model=\"ProsusAI/finbert\", top_k=None)\n\n# Pfad zu den Ordnern\ninput_folder = \"/kaggle/input/llm-text/TEXT/EZB/\"\n\n# Alle Datums-Ordner durchgehen\ndate_folders = [f for f in os.listdir(input_folder) if os.path.isdir(os.path.join(input_folder, f))]\n\nresults = []\n\ndef simple_sentence_split(text):\n    sentences = re.split(r'[.!?]+', text)\n    sentences = [s.strip() for s in sentences if len(s.strip()) > 20]\n    return sentences\n\nfor date_folder in date_folders:\n    full_file = os.path.join(input_folder, date_folder, \"0_FULL.txt\")\n    \n    if os.path.exists(full_file):\n        if SHOW_PROGRESS:\n            print(f\"Verarbeite: {date_folder}\")\n        \n        # Datei lesen\n        with open(full_file, 'r', encoding='utf-8') as file:\n            text = file.read()\n        \n        # Satz-basierte Analyse\n        sentences = simple_sentence_split(text)\n        optimism_scores_sentences = []\n        for sentence in sentences:\n            if len(sentence.strip()) > 10:\n                result = sentiment_analyzer(sentence)\n                labels = {r['label']: r['score'] for r in result[0]}\n                neg_prob = labels.get('negative', 0)\n                pos_prob = labels.get('positive', 0)\n                optimism_score = pos_prob - neg_prob\n                optimism_scores_sentences.append(optimism_score)\n        overall_optimism_sentences = sum(optimism_scores_sentences) / len(optimism_scores_sentences) if optimism_scores_sentences else 0\n        \n        # Chunk-basierte Analyse\n        chunks = [text[i:i+512] for i in range(0, len(text), 400) if len(text[i:i+512].strip()) > 50]\n        optimism_scores_chunks = []\n        for chunk in chunks:\n            result = sentiment_analyzer(chunk)\n            labels = {r['label']: r['score'] for r in result[0]}\n            neg_prob = labels.get('negative', 0)\n            pos_prob = labels.get('positive', 0)\n            optimism_score = pos_prob - neg_prob\n            optimism_scores_chunks.append(optimism_score)\n        overall_optimism_chunks = sum(optimism_scores_chunks) / len(optimism_scores_chunks) if optimism_scores_chunks else 0\n        \n        # Ergebnisse speichern\n        row = {\n            'Date': date_folder,\n            'Optimism_Score_Sentences': round(overall_optimism_sentences, 3),\n            'Sentence_Count': len(optimism_scores_sentences),\n            'Optimism_Score_Chunks': round(overall_optimism_chunks, 3),\n            'Chunk_Count': len(optimism_scores_chunks)\n        }\n        results.append(row)\n\n# DataFrame erstellen\ndf = pd.DataFrame(results)\n\n# CHRONOLOGISCHE SORTIERUNG\ndef parse_date(date_str):\n    try:\n        parts = date_str.split('_')\n        if len(parts) == 3:\n            day, month, year = parts\n            return datetime.strptime(f\"{day} {month} {year}\", \"%d %B %Y\")\n        else:\n            return datetime.max\n    except:\n        return datetime.max\n\ndf['Parsed_Date'] = df['Date'].apply(parse_date)\ndf_sorted = df.sort_values('Parsed_Date').drop(columns=['Parsed_Date'])\n\n# Excel speichern\nexcel_path = 'ezb_optimism_scores_compare_sentences_chunks_finbert.xlsx'\ndf_sorted.to_excel(excel_path, index=False)\n\nprint(df_sorted.to_string(index=False))\nprint(f\"Ergebnisse wurden in '{excel_path}' gespeichert.\")\n\n# Einfacher Download-Link\ndisplay(FileLink(excel_path))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:42:26.669574Z","iopub.execute_input":"2025-07-02T20:42:26.669779Z","iopub.status.idle":"2025-07-02T20:43:02.259204Z","shell.execute_reply.started":"2025-07-02T20:42:26.669763Z","shell.execute_reply":"2025-07-02T20:43:02.258457Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Verarbeite: 17_October_2024\nVerarbeite: 17_April_2025\nVerarbeite: 14_December_2023\nVerarbeite: 11_April_2024\nVerarbeite: 12_December_2024\nVerarbeite: 21_July_2022\nVerarbeite: 08_September_2022\nVerarbeite: 14_September_2023\nVerarbeite: 12_September_2024\nVerarbeite: 07_March_2024\nVerarbeite: 27_October_2022\nVerarbeite: 16_March_2023\nVerarbeite: 06_March_2025\nVerarbeite: 26_October_2023\nVerarbeite: 27_July_2023\nVerarbeite: 25_January_2024\nVerarbeite: 02_February_2023\nVerarbeite: 30_January_2025\nVerarbeite: 18_July_2024\nVerarbeite: 05_June_2025\nVerarbeite: 09_June_2022\nVerarbeite: 15_December_2022\nVerarbeite: 15_June_2023\nVerarbeite: 04_May_2023\nVerarbeite: 06_June_2024\n             Date  Optimism_Score_Sentences  Sentence_Count  Optimism_Score_Chunks  Chunk_Count\n     09_June_2022                     0.208             138                  0.119           46\n     21_July_2022                     0.268             109                  0.245           39\n08_September_2022                     0.045             111                 -0.006           39\n  27_October_2022                     0.111             101                  0.096           36\n 15_December_2022                     0.040             139                 -0.195           45\n 02_February_2023                     0.127             111                  0.003           41\n    16_March_2023                     0.115             120                  0.030           39\n      04_May_2023                     0.060             105                  0.088           36\n     15_June_2023                    -0.037             126                 -0.270           40\n     27_July_2023                     0.050             108                 -0.018           37\n14_September_2023                     0.060             120                 -0.126           37\n  26_October_2023                    -0.003             124                 -0.142           34\n 14_December_2023                     0.044             141                 -0.255           41\n  25_January_2024                    -0.024              86                 -0.185           30\n    07_March_2024                    -0.008             113                 -0.230           33\n    11_April_2024                     0.085             102                 -0.191           33\n     06_June_2024                     0.164             130                 -0.084           38\n     18_July_2024                     0.143             101                 -0.113           32\n12_September_2024                     0.055             143                 -0.387           41\n  17_October_2024                     0.071             107                 -0.283           34\n 12_December_2024                     0.121             144                 -0.103           40\n  30_January_2025                     0.208             106                  0.059           35\n    06_March_2025                     0.129             137                 -0.141           35\n    17_April_2025                    -0.031             113                 -0.410           35\n     05_June_2025                     0.155             132                 -0.095           42\nErgebnisse wurden in 'ezb_optimism_scores_compare_sentences_chunks_finbert.xlsx' gespeichert.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/ezb_optimism_scores_compare_sentences_chunks_finbert.xlsx","text/html":"<a href='ezb_optimism_scores_compare_sentences_chunks_finbert.xlsx' target='_blank'>ezb_optimism_scores_compare_sentences_chunks_finbert.xlsx</a><br>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"#optimierte Sätze-finbert!!!\n\n\nfrom transformers import pipeline\nimport os\nimport pandas as pd\nfrom datetime import datetime\nfrom IPython.display import FileLink\nimport nltk\nfrom nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n\n# NLTK Punkt Daten herunterladen (einmalig)\nnltk.download('punkt')\n\n# OPTION: Ausgabe ein/ausschalten\nSHOW_PROGRESS = True\n\n# Model laden\nsentiment_analyzer = pipeline(\"text-classification\", model=\"ProsusAI/finbert\", top_k=None)\n\n# Pfad zu den Ordnern\ninput_folder = \"/kaggle/input/llm-text/TEXT/EZB/\"\n\n# Alle Datums-Ordner durchgehen\ndate_folders = [f for f in os.listdir(input_folder) if os.path.isdir(os.path.join(input_folder, f))]\n\nresults = []\n\ndef improved_sentence_split(text):\n    # Punkt-Parameter für EZB-spezifische Abkürzungen\n    punkt_param = PunktParameters()\n    punkt_param.abbrev_types = set([\n        'mr', 'mrs', 'ms', 'dr', 'prof',  # Titel\n        'e.g', 'i.e', 'etc', 'vs', 'cf',  # Lateinische Abkürzungen\n        'ecb', 'eu', 'euro', 'gdp', 'cpi', 'ppp',  # Finanz-Abkürzungen\n        'u.s', 'u.k', 'u.s.a', 'e.u',  # Länder\n        'jan', 'feb', 'mar', 'apr', 'may', 'jun',  # Monate\n        'jul', 'aug', 'sep', 'oct', 'nov', 'dec',\n        'inc', 'ltd', 'corp', 'co', 'llc',  # Unternehmen\n        'no', 'nos', 'vol', 'p', 'pp', 'fig',  # Allgemeine Abkürzungen\n        'tel', 'fax', 'email', 'www'  # Kontakt-Abkürzungen\n    ])\n    \n    # Tokenizer mit angepassten Parametern\n    tokenizer = PunktSentenceTokenizer(punkt_param)\n    \n    # Text in Sätze aufteilen\n    sentences = tokenizer.tokenize(text)\n    \n    # Filtere zu kurze Sätze und bereinige\n    sentences = [s.strip() for s in sentences if len(s.strip()) > 20]\n    \n    return sentences\n\nfor date_folder in date_folders:\n    full_file = os.path.join(input_folder, date_folder, \"0_FULL.txt\")\n    \n    if os.path.exists(full_file):\n        if SHOW_PROGRESS:\n            print(f\"Verarbeite: {date_folder}\")\n        \n        # Datei lesen\n        with open(full_file, 'r', encoding='utf-8') as file:\n            text = file.read()\n        \n        # Satz-basierte Analyse mit verbessertem Tokenizer\n        sentences = improved_sentence_split(text)\n        optimism_scores_sentences = []\n        for sentence in sentences:\n            if len(sentence.strip()) > 10:\n                result = sentiment_analyzer(sentence)\n                labels = {r['label']: r['score'] for r in result[0]}\n                neg_prob = labels.get('negative', 0)\n                pos_prob = labels.get('positive', 0)\n                optimism_score = pos_prob - neg_prob\n                optimism_scores_sentences.append(optimism_score)\n        overall_optimism_sentences = sum(optimism_scores_sentences) / len(optimism_scores_sentences) if optimism_scores_sentences else 0\n        \n        # Chunk-basierte Analyse\n        chunks = [text[i:i+512] for i in range(0, len(text), 400) if len(text[i:i+512].strip()) > 50]\n        optimism_scores_chunks = []\n        for chunk in chunks:\n            result = sentiment_analyzer(chunk)\n            labels = {r['label']: r['score'] for r in result[0]}\n            neg_prob = labels.get('negative', 0)\n            pos_prob = labels.get('positive', 0)\n            optimism_score = pos_prob - neg_prob\n            optimism_scores_chunks.append(optimism_score)\n        overall_optimism_chunks = sum(optimism_scores_chunks) / len(optimism_scores_chunks) if optimism_scores_chunks else 0\n        \n        # Ergebnisse speichern\n        row = {\n            'Date': date_folder,\n            'Optimism_Score_Sentences': round(overall_optimism_sentences, 3),\n            'Sentence_Count': len(optimism_scores_sentences),\n            'Optimism_Score_Chunks': round(overall_optimism_chunks, 3),\n            'Chunk_Count': len(optimism_scores_chunks)\n        }\n        results.append(row)\n\n# DataFrame erstellen\ndf = pd.DataFrame(results)\n\n# CHRONOLOGISCHE SORTIERUNG\ndef parse_date(date_str):\n    try:\n        parts = date_str.split('_')\n        if len(parts) == 3:\n            day, month, year = parts\n            return datetime.strptime(f\"{day} {month} {year}\", \"%d %B %Y\")\n        else:\n            return datetime.max\n    except:\n        return datetime.max\n\ndf['Parsed_Date'] = df['Date'].apply(parse_date)\ndf_sorted = df.sort_values('Parsed_Date').drop(columns=['Parsed_Date'])\n\n# Excel speichern\nexcel_path = 'ezb_optimism_scores_compare_sentences_chunks_finbert_improved.xlsx'\ndf_sorted.to_excel(excel_path, index=False)\n\nprint(df_sorted.to_string(index=False))\nprint(f\"Ergebnisse wurden in '{excel_path}' gespeichert.\")\n\n# Einfacher Download-Link\ndisplay(FileLink(excel_path))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:43:02.260026Z","iopub.execute_input":"2025-07-02T20:43:02.260204Z","iopub.status.idle":"2025-07-02T20:43:34.037566Z","shell.execute_reply.started":"2025-07-02T20:43:02.260190Z","shell.execute_reply":"2025-07-02T20:43:34.036942Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Verarbeite: 17_October_2024\nVerarbeite: 17_April_2025\nVerarbeite: 14_December_2023\nVerarbeite: 11_April_2024\nVerarbeite: 12_December_2024\nVerarbeite: 21_July_2022\nVerarbeite: 08_September_2022\nVerarbeite: 14_September_2023\nVerarbeite: 12_September_2024\nVerarbeite: 07_March_2024\nVerarbeite: 27_October_2022\nVerarbeite: 16_March_2023\nVerarbeite: 06_March_2025\nVerarbeite: 26_October_2023\nVerarbeite: 27_July_2023\nVerarbeite: 25_January_2024\nVerarbeite: 02_February_2023\nVerarbeite: 30_January_2025\nVerarbeite: 18_July_2024\nVerarbeite: 05_June_2025\nVerarbeite: 09_June_2022\nVerarbeite: 15_December_2022\nVerarbeite: 15_June_2023\nVerarbeite: 04_May_2023\nVerarbeite: 06_June_2024\n             Date  Optimism_Score_Sentences  Sentence_Count  Optimism_Score_Chunks  Chunk_Count\n     09_June_2022                     0.196             123                  0.119           46\n     21_July_2022                     0.260             104                  0.245           39\n08_September_2022                     0.012              98                 -0.006           39\n  27_October_2022                     0.070              94                  0.096           36\n 15_December_2022                    -0.024             113                 -0.195           45\n 02_February_2023                     0.106             102                  0.003           41\n    16_March_2023                     0.077              98                  0.030           39\n      04_May_2023                     0.044              92                  0.088           36\n     15_June_2023                    -0.117             109                 -0.270           40\n     27_July_2023                     0.026              93                 -0.018           37\n14_September_2023                    -0.021              98                 -0.126           37\n  26_October_2023                    -0.066             102                 -0.142           34\n 14_December_2023                    -0.016             116                 -0.255           41\n  25_January_2024                    -0.053              78                 -0.185           30\n    07_March_2024                    -0.032              88                 -0.230           33\n    11_April_2024                     0.044              83                 -0.191           33\n     06_June_2024                     0.127             106                 -0.084           38\n     18_July_2024                     0.047              88                 -0.113           32\n12_September_2024                    -0.048             117                 -0.387           41\n  17_October_2024                     0.037              98                 -0.283           34\n 12_December_2024                     0.092             116                 -0.103           40\n  30_January_2025                     0.150              95                  0.059           35\n    06_March_2025                     0.052             101                 -0.141           35\n    17_April_2025                    -0.095              94                 -0.410           35\n     05_June_2025                     0.118             107                 -0.095           42\nErgebnisse wurden in 'ezb_optimism_scores_compare_sentences_chunks_finbert_improved.xlsx' gespeichert.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/ezb_optimism_scores_compare_sentences_chunks_finbert_improved.xlsx","text/html":"<a href='ezb_optimism_scores_compare_sentences_chunks_finbert_improved.xlsx' target='_blank'>ezb_optimism_scores_compare_sentences_chunks_finbert_improved.xlsx</a><br>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"#optimierte Sätze-financial-roberta\nfrom transformers import pipeline\nimport os\nimport pandas as pd\nfrom datetime import datetime\nfrom IPython.display import FileLink\nimport nltk\nfrom nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n\n# NLTK Punkt Daten herunterladen (einmalig)\nnltk.download('punkt')\n\n# OPTION: Ausgabe ein/ausschalten\nSHOW_PROGRESS = True\n\n# Model laden\nsentiment_analyzer = pipeline(\"text-classification\", model=\"soleimanian/financial-roberta-large-sentiment\", top_k=None)\n\n# Pfad zu den Ordnern\ninput_folder = \"/kaggle/input/llm-text/TEXT/EZB/\"\n\n# Alle Datums-Ordner durchgehen\ndate_folders = [f for f in os.listdir(input_folder) if os.path.isdir(os.path.join(input_folder, f))]\n\nresults = []\n\ndef improved_sentence_split(text):\n    # Punkt-Parameter für EZB-spezifische Abkürzungen\n    punkt_param = PunktParameters()\n    punkt_param.abbrev_types = set([\n        'mr', 'mrs', 'ms', 'dr', 'prof',  # Titel\n        'e.g', 'i.e', 'etc', 'vs', 'cf',  # Lateinische Abkürzungen\n        'ecb', 'eu', 'euro', 'gdp', 'cpi', 'ppp',  # Finanz-Abkürzungen\n        'u.s', 'u.k', 'u.s.a', 'e.u',  # Länder\n        'jan', 'feb', 'mar', 'apr', 'may', 'jun',  # Monate\n        'jul', 'aug', 'sep', 'oct', 'nov', 'dec',\n        'inc', 'ltd', 'corp', 'co', 'llc',  # Unternehmen\n        'no', 'nos', 'vol', 'p', 'pp', 'fig',  # Allgemeine Abkürzungen\n        'tel', 'fax', 'email', 'www'  # Kontakt-Abkürzungen\n    ])\n    \n    # Tokenizer mit angepassten Parametern\n    tokenizer = PunktSentenceTokenizer(punkt_param)\n    \n    # Text in Sätze aufteilen\n    sentences = tokenizer.tokenize(text)\n    \n    # Filtere zu kurze Sätze und bereinige\n    sentences = [s.strip() for s in sentences if len(s.strip()) > 20]\n    \n    return sentences\n\nfor date_folder in date_folders:\n    full_file = os.path.join(input_folder, date_folder, \"0_FULL.txt\")\n    \n    if os.path.exists(full_file):\n        if SHOW_PROGRESS:\n            print(f\"Verarbeite: {date_folder}\")\n        \n        # Datei lesen\n        with open(full_file, 'r', encoding='utf-8') as file:\n            text = file.read()\n        \n        # Satz-basierte Analyse mit verbessertem Tokenizer\n        sentences = improved_sentence_split(text)\n        optimism_scores_sentences = []\n        for sentence in sentences:\n            if len(sentence.strip()) > 10:\n                result = sentiment_analyzer(sentence)\n                labels = {r['label']: r['score'] for r in result[0]}\n                neg_prob = labels.get('negative', 0)\n                pos_prob = labels.get('positive', 0)\n                optimism_score = pos_prob - neg_prob\n                optimism_scores_sentences.append(optimism_score)\n        overall_optimism_sentences = sum(optimism_scores_sentences) / len(optimism_scores_sentences) if optimism_scores_sentences else 0\n        \n        # Chunk-basierte Analyse\n        chunks = [text[i:i+512] for i in range(0, len(text), 400) if len(text[i:i+512].strip()) > 50]\n        optimism_scores_chunks = []\n        for chunk in chunks:\n            result = sentiment_analyzer(chunk)\n            labels = {r['label']: r['score'] for r in result[0]}\n            neg_prob = labels.get('negative', 0)\n            pos_prob = labels.get('positive', 0)\n            optimism_score = pos_prob - neg_prob\n            optimism_scores_chunks.append(optimism_score)\n        overall_optimism_chunks = sum(optimism_scores_chunks) / len(optimism_scores_chunks) if optimism_scores_chunks else 0\n        \n        # Ergebnisse speichern\n        row = {\n            'Date': date_folder,\n            'Optimism_Score_Sentences': round(overall_optimism_sentences, 3),\n            'Sentence_Count': len(optimism_scores_sentences),\n            'Optimism_Score_Chunks': round(overall_optimism_chunks, 3),\n            'Chunk_Count': len(optimism_scores_chunks)\n        }\n        results.append(row)\n\n# DataFrame erstellen\ndf = pd.DataFrame(results)\n\n# CHRONOLOGISCHE SORTIERUNG\ndef parse_date(date_str):\n    try:\n        parts = date_str.split('_')\n        if len(parts) == 3:\n            day, month, year = parts\n            return datetime.strptime(f\"{day} {month} {year}\", \"%d %B %Y\")\n        else:\n            return datetime.max\n    except:\n        return datetime.max\n\ndf['Parsed_Date'] = df['Date'].apply(parse_date)\ndf_sorted = df.sort_values('Parsed_Date').drop(columns=['Parsed_Date'])\n\n# Excel speichern\nexcel_path = 'ezb_optimism_scores_compare_sentences_chunks_financial_roberta_improved.xlsx'\ndf_sorted.to_excel(excel_path, index=False)\n\nprint(df_sorted.to_string(index=False))\nprint(f\"Ergebnisse wurden in '{excel_path}' gespeichert.\")\n\n# Einfacher Download-Link\ndisplay(FileLink(excel_path))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:43:34.038323Z","iopub.execute_input":"2025-07-02T20:43:34.038532Z","iopub.status.idle":"2025-07-02T20:44:51.239451Z","shell.execute_reply.started":"2025-07-02T20:43:34.038516Z","shell.execute_reply":"2025-07-02T20:44:51.238855Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Verarbeite: 17_October_2024\nVerarbeite: 17_April_2025\nVerarbeite: 14_December_2023\nVerarbeite: 11_April_2024\nVerarbeite: 12_December_2024\nVerarbeite: 21_July_2022\nVerarbeite: 08_September_2022\nVerarbeite: 14_September_2023\nVerarbeite: 12_September_2024\nVerarbeite: 07_March_2024\nVerarbeite: 27_October_2022\nVerarbeite: 16_March_2023\nVerarbeite: 06_March_2025\nVerarbeite: 26_October_2023\nVerarbeite: 27_July_2023\nVerarbeite: 25_January_2024\nVerarbeite: 02_February_2023\nVerarbeite: 30_January_2025\nVerarbeite: 18_July_2024\nVerarbeite: 05_June_2025\nVerarbeite: 09_June_2022\nVerarbeite: 15_December_2022\nVerarbeite: 15_June_2023\nVerarbeite: 04_May_2023\nVerarbeite: 06_June_2024\n             Date  Optimism_Score_Sentences  Sentence_Count  Optimism_Score_Chunks  Chunk_Count\n     09_June_2022                     0.036             123                 -0.069           46\n     21_July_2022                     0.094             104                  0.231           39\n08_September_2022                    -0.174              98                 -0.245           39\n  27_October_2022                    -0.058              94                 -0.004           36\n 15_December_2022                    -0.102             113                 -0.140           45\n 02_February_2023                     0.059             102                  0.069           41\n    16_March_2023                    -0.105              98                 -0.073           39\n      04_May_2023                    -0.015              92                 -0.229           36\n     15_June_2023                    -0.167             109                 -0.240           40\n     27_July_2023                     0.016              93                 -0.085           37\n14_September_2023                     0.038              98                 -0.175           37\n  26_October_2023                    -0.114             102                 -0.161           34\n 14_December_2023                    -0.061             116                 -0.178           41\n  25_January_2024                    -0.032              78                 -0.178           30\n    07_March_2024                     0.015              88                 -0.027           33\n    11_April_2024                     0.091              83                 -0.056           33\n     06_June_2024                     0.081             106                  0.119           38\n     18_July_2024                    -0.074              88                 -0.255           32\n12_September_2024                    -0.042             117                 -0.055           41\n  17_October_2024                    -0.080              98                 -0.108           34\n 12_December_2024                     0.058             116                  0.133           40\n  30_January_2025                     0.002              95                 -0.020           35\n    06_March_2025                    -0.064             101                 -0.091           35\n    17_April_2025                    -0.036              94                  0.064           35\n     05_June_2025                     0.031             107                 -0.043           42\nErgebnisse wurden in 'ezb_optimism_scores_compare_sentences_chunks_financial_roberta_improved.xlsx' gespeichert.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/ezb_optimism_scores_compare_sentences_chunks_financial_roberta_improved.xlsx","text/html":"<a href='ezb_optimism_scores_compare_sentences_chunks_financial_roberta_improved.xlsx' target='_blank'>ezb_optimism_scores_compare_sentences_chunks_financial_roberta_improved.xlsx</a><br>"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"# all Modells compared","metadata":{}},{"cell_type":"code","source":"#complete Evaluation LLM Models\nfrom transformers import pipeline\nimport os\nimport pandas as pd\nfrom datetime import datetime\nfrom IPython.display import FileLink\nimport nltk\nfrom nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n\n# Download NLTK Punkt data (one-time)\nnltk.download('punkt')\n\n# OPTION: Enable/disable output\nSHOW_PROGRESS = True\n\n# Load both models\nfinbert_analyzer = pipeline(\"text-classification\", model=\"ProsusAI/finbert\", top_k=None)\nroberta_analyzer = pipeline(\"text-classification\", model=\"soleimanian/financial-roberta-large-sentiment\", top_k=None)\n\n# Path to folders\ninput_folder = \"/kaggle/input/llm-test-text/TEXT_TEST/\"\n\n# Process all date folders\ndate_folders = [f for f in os.listdir(input_folder) if os.path.isdir(os.path.join(input_folder, f))]\n\nresults = []\n\ndef improved_sentence_split(text):\n    # Punkt parameters for ECB-specific abbreviations\n    punkt_param = PunktParameters()\n    punkt_param.abbrev_types = set([\n        'mr', 'mrs', 'ms', 'dr', 'prof',  # Titles\n        'e.g', 'i.e', 'etc', 'vs', 'cf',  # Latin abbreviations\n        'ecb', 'eu', 'euro', 'gdp', 'cpi', 'ppp',  # Financial abbreviations\n        'u.s', 'u.k', 'u.s.a', 'e.u',  # Countries\n        'jan', 'feb', 'mar', 'apr', 'may', 'jun',  # Months\n        'jul', 'aug', 'sep', 'oct', 'nov', 'dec',\n        'inc', 'ltd', 'corp', 'co', 'llc',  # Companies\n        'no', 'nos', 'vol', 'p', 'pp', 'fig',  # General abbreviations\n        'tel', 'fax', 'email', 'www'  # Contact abbreviations\n    ])\n    \n    # Tokenizer with adjusted parameters\n    tokenizer = PunktSentenceTokenizer(punkt_param)\n    \n    # Split text into sentences\n    sentences = tokenizer.tokenize(text)\n    \n    # Filter short sentences and clean\n    sentences = [s.strip() for s in sentences if len(s.strip()) > 20]\n    \n    return sentences\n\ndef analyze_with_model(analyzer, text_input):\n    \"\"\"Helper function for sentiment analysis\"\"\"\n    result = analyzer(text_input)\n    labels = {r['label']: r['score'] for r in result[0]}\n    neg_prob = labels.get('negative', 0)\n    pos_prob = labels.get('positive', 0)\n    return pos_prob - neg_prob\n\nfor date_folder in date_folders:\n    full_file = os.path.join(input_folder, date_folder, \"0_FULL.txt\")\n    \n    if os.path.exists(full_file):\n        if SHOW_PROGRESS:\n            print(f\"Processing: {date_folder}\")\n        \n        # Read file\n        with open(full_file, 'r', encoding='utf-8') as file:\n            text = file.read()\n        \n        # Prepare sentences and chunks\n        sentences = improved_sentence_split(text)\n        chunks = [text[i:i+512] for i in range(0, len(text), 400) if len(text[i:i+512].strip()) > 50]\n        \n        # FinBERT sentence analysis\n        finbert_sentence_scores = []\n        for sentence in sentences:\n            if len(sentence.strip()) > 10:\n                score = analyze_with_model(finbert_analyzer, sentence)\n                finbert_sentence_scores.append(score)\n        finbert_sentences_avg = sum(finbert_sentence_scores) / len(finbert_sentence_scores) if finbert_sentence_scores else 0\n        \n        # FinBERT chunk analysis\n        finbert_chunk_scores = []\n        for chunk in chunks:\n            score = analyze_with_model(finbert_analyzer, chunk)\n            finbert_chunk_scores.append(score)\n        finbert_chunks_avg = sum(finbert_chunk_scores) / len(finbert_chunk_scores) if finbert_chunk_scores else 0\n        \n        # Financial-RoBERTa sentence analysis\n        roberta_sentence_scores = []\n        for sentence in sentences:\n            if len(sentence.strip()) > 10:\n                score = analyze_with_model(roberta_analyzer, sentence)\n                roberta_sentence_scores.append(score)\n        roberta_sentences_avg = sum(roberta_sentence_scores) / len(roberta_sentence_scores) if roberta_sentence_scores else 0\n        \n        # Financial-RoBERTa chunk analysis\n        roberta_chunk_scores = []\n        for chunk in chunks:\n            score = analyze_with_model(roberta_analyzer, chunk)\n            roberta_chunk_scores.append(score)\n        roberta_chunks_avg = sum(roberta_chunk_scores) / len(roberta_chunk_scores) if roberta_chunk_scores else 0\n        \n        # Store results\n        row = {\n            'Date': date_folder,\n            'FinBERT_Sentences': round(finbert_sentences_avg, 3),\n            'FinBERT_Chunks': round(finbert_chunks_avg, 3),\n            'RoBERTa_Sentences': round(roberta_sentences_avg, 3),\n            'RoBERTa_Chunks': round(roberta_chunks_avg, 3),\n            'Sentence_Count': len(finbert_sentence_scores),\n            'Chunk_Count': len(finbert_chunk_scores)\n        }\n        results.append(row)\n\n# Create DataFrame\ndf = pd.DataFrame(results)\n\n# CHRONOLOGICAL SORTING\ndef parse_date(date_str):\n    try:\n        parts = date_str.split('_')\n        if len(parts) == 3:\n            day, month, year = parts\n            return datetime.strptime(f\"{day} {month} {year}\", \"%d %B %Y\")\n        else:\n            return datetime.max\n    except:\n        return datetime.max\n\ndf['Parsed_Date'] = df['Date'].apply(parse_date)\ndf_sorted = df.sort_values('Parsed_Date').drop(columns=['Parsed_Date'])\n\n# Additional analysis: Consistency check\ndf_sorted['FinBERT_Difference'] = abs(df_sorted['FinBERT_Sentences'] - df_sorted['FinBERT_Chunks'])\ndf_sorted['RoBERTa_Difference'] = abs(df_sorted['RoBERTa_Sentences'] - df_sorted['RoBERTa_Chunks'])\n\n# ADD AVERAGE ROW\naverage_row = df_sorted.select_dtypes(include=['number']).mean()\naverage_row['Date'] = 'Average'\ndf_with_average = pd.concat([df_sorted, average_row.to_frame().T], ignore_index=True)\n\nprint(\"=== COMPLETE MODEL COMPARISON ===\")\nprint(df_with_average.to_string(index=False))\nprint(f\"FinBERT average difference sentences/chunks: {df_sorted['FinBERT_Difference'].mean():.3f}\")\nprint(f\"RoBERTa average difference sentences/chunks: {df_sorted['RoBERTa_Difference'].mean():.3f}\")\n\n# ===========================================\n# SAVE TO EXCEL WITH MULTIPLE SHEETS\n# ===========================================\n\n# Generate LaTeX table content WITH AVERAGE ROW\nlatex_table = df_with_average[['Date', 'FinBERT_Sentences', 'RoBERTa_Sentences', 'Sentence_Count']].to_latex(\n    index=False, \n    float_format=\"%.3f\",\n    caption=\"ECB Sentiment Analysis Results Comparison\",\n    label=\"tab:sentiment_comparison\",\n    column_format=\"llrr\"\n)\n\n# Generate summary report content\nreport = f\"\"\"ECB SENTIMENT ANALYSIS REPORT\n============================\n\nDataset Overview:\n- Total Documents Analyzed: {len(df_sorted)}\n- Date Range: {df_sorted['Date'].min()} to {df_sorted['Date'].max()}\n- Average Sentences per Document: {df_sorted['Sentence_Count'].mean():.1f}\n- Average Chunks per Document: {df_sorted['Chunk_Count'].mean():.1f}\n\nModel Performance Comparison:\n- FinBERT Average Sentiment (Sentences): {df_sorted['FinBERT_Sentences'].mean():.3f}\n- RoBERTa Average Sentiment (Sentences): {df_sorted['RoBERTa_Sentences'].mean():.3f}\n- Correlation between FinBERT and RoBERTa: {df_sorted['FinBERT_Sentences'].corr(df_sorted['RoBERTa_Sentences']):.3f}\n\nSentiment Range Analysis:\n- FinBERT Min/Max: {df_sorted['FinBERT_Sentences'].min():.3f} / {df_sorted['FinBERT_Sentences'].max():.3f}\n- RoBERTa Min/Max: {df_sorted['RoBERTa_Sentences'].min():.3f} / {df_sorted['RoBERTa_Sentences'].max():.3f}\n\nConsistency Analysis (Sentences vs Chunks):\n- FinBERT Consistency Score: {1 - df_sorted['FinBERT_Difference'].mean():.3f}\n- RoBERTa Consistency Score: {1 - df_sorted['RoBERTa_Difference'].mean():.3f}\n\nMost Positive Sentiment:\n- Date: {df_sorted.loc[df_sorted['FinBERT_Sentences'].idxmax(), 'Date']}\n- FinBERT Score: {df_sorted['FinBERT_Sentences'].max():.3f}\n\nMost Negative Sentiment:\n- Date: {df_sorted.loc[df_sorted['FinBERT_Sentences'].idxmin(), 'Date']}\n- FinBERT Score: {df_sorted['FinBERT_Sentences'].min():.3f}\"\"\"\n\n# Save Excel with multiple sheets\nexcel_path = 'ezb_optimism_scores_ALL_MODELS_COMPARISON.xlsx'\n\nwith pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n    # Main data sheet with average row\n    df_with_average.to_excel(writer, sheet_name='Data', index=False)\n    \n    # LaTeX table sheet\n    latex_df = pd.DataFrame([latex_table], columns=['LaTeX_Table'])\n    latex_df.to_excel(writer, sheet_name='LaTeX_Table', index=False, header=False)\n    \n    # Summary report sheet\n    report_df = pd.DataFrame([report], columns=['Summary_Report'])\n    report_df.to_excel(writer, sheet_name='Summary_Report', index=False, header=False)\n\nprint(f\"\\n✅ Complete file saved: {excel_path}\")\nprint(\"Sheets: Data (with Average row), LaTeX_Table (with Average row), Summary_Report\")\n\n# Download link\ndisplay(FileLink(excel_path))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:44:51.240323Z","iopub.execute_input":"2025-07-02T20:44:51.240572Z","iopub.status.idle":"2025-07-02T20:45:23.649245Z","shell.execute_reply.started":"2025-07-02T20:44:51.240528Z","shell.execute_reply":"2025-07-02T20:45:23.648405Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nDevice set to use cuda:0\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Processing: 17_October_2024\nProcessing: 17_April_2025\nProcessing: 12_December_2024\nProcessing: 12_September_2024\nProcessing: 06_March_2025\nProcessing: 30_January_2025\nProcessing: 05_June_2025\n=== COMPLETE MODEL COMPARISON ===\n             Date FinBERT_Sentences FinBERT_Chunks RoBERTa_Sentences RoBERTa_Chunks Sentence_Count Chunk_Count FinBERT_Difference RoBERTa_Difference\n12_September_2024            -0.048         -0.387            -0.042         -0.055            117          41              0.339              0.013\n  17_October_2024             0.037         -0.283             -0.08         -0.108             98          34               0.32              0.028\n 12_December_2024             0.092         -0.103             0.058          0.133            116          40              0.195              0.075\n  30_January_2025              0.15          0.059             0.002          -0.02             95          35              0.091              0.022\n    06_March_2025             0.052         -0.141            -0.064         -0.091            101          35              0.193              0.027\n    17_April_2025            -0.095          -0.41            -0.036          0.064             94          35              0.315                0.1\n     05_June_2025             0.118         -0.095             0.031         -0.043            107          42              0.213              0.074\n          Average          0.043714      -0.194286         -0.018714      -0.017143          104.0   37.428571              0.238           0.048429\nFinBERT average difference sentences/chunks: 0.238\nRoBERTa average difference sentences/chunks: 0.048\n\n✅ Complete file saved: ezb_optimism_scores_ALL_MODELS_COMPARISON.xlsx\nSheets: Data (with Average row), LaTeX_Table (with Average row), Summary_Report\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/ezb_optimism_scores_ALL_MODELS_COMPARISON.xlsx","text/html":"<a href='ezb_optimism_scores_ALL_MODELS_COMPARISON.xlsx' target='_blank'>ezb_optimism_scores_ALL_MODELS_COMPARISON.xlsx</a><br>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Interpretation","metadata":{}},{"cell_type":"code","source":"#complete Evaluation LLM Models\nfrom transformers import pipeline\nimport os\nimport pandas as pd\nfrom datetime import datetime\nfrom IPython.display import FileLink\nimport nltk\nfrom nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n\n# Download NLTK Punkt data (one-time)\nnltk.download('punkt')\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\nCONFIG = {\n    'main_excel_filename': 'ecb_sentiment_analysis.xlsx',            \n    'detailed_excel_filename': 'sentiment_analysis_details.xlsx'\n}\n\n# OPTION: Enable/disable output\nSHOW_PROGRESS = True\n\n# Load both models\nfinbert_analyzer = pipeline(\"text-classification\", model=\"ProsusAI/finbert\", top_k=None)\nroberta_analyzer = pipeline(\"text-classification\", model=\"soleimanian/financial-roberta-large-sentiment\", top_k=None)\n\n# Path to folders\ninput_folder = \"/kaggle/input/llm-text/TEXT/EZB/\"\n\n\n# Process all date folders\ndate_folders = [f for f in os.listdir(input_folder) if os.path.isdir(os.path.join(input_folder, f))]\n\nresults = []\n\ndef improved_sentence_split(text):\n    # Punkt parameters for ECB-specific abbreviations\n    punkt_param = PunktParameters()\n    punkt_param.abbrev_types = set([\n        'mr', 'mrs', 'ms', 'dr', 'prof',  # Titles\n        'e.g', 'i.e', 'etc', 'vs', 'cf',  # Latin abbreviations\n        'ecb', 'eu', 'euro', 'gdp', 'cpi', 'ppp',  # Financial abbreviations\n        'u.s', 'u.k', 'u.s.a', 'e.u',  # Countries\n        'jan', 'feb', 'mar', 'apr', 'may', 'jun',  # Months\n        'jul', 'aug', 'sep', 'oct', 'nov', 'dec',\n        'inc', 'ltd', 'corp', 'co', 'llc',  # Companies\n        'no', 'nos', 'vol', 'p', 'pp', 'fig',  # General abbreviations\n        'tel', 'fax', 'email', 'www'  # Contact abbreviations\n    ])\n    \n    # Tokenizer with adjusted parameters\n    tokenizer = PunktSentenceTokenizer(punkt_param)\n    \n    # Split text into sentences\n    sentences = tokenizer.tokenize(text)\n    \n    # Filter short sentences and clean\n    sentences = [s.strip() for s in sentences if len(s.strip()) > 20]\n    \n    return sentences\n\ndef analyze_with_model(analyzer, text_input):\n    \"\"\"Helper function for sentiment analysis\"\"\"\n    result = analyzer(text_input)\n    labels = {r['label']: r['score'] for r in result[0]}\n    neg_prob = labels.get('negative',0)\n    pos_prob = labels.get('positive',0)\n    return pos_prob - neg_prob\n\nfor date_folder in date_folders:\n    full_file = os.path.join(input_folder, date_folder, \"0_FULL.txt\")\n    \n    if os.path.exists(full_file):\n        if SHOW_PROGRESS:\n            print(f\"Processing: {date_folder}\")\n        \n        # Read file\n        with open(full_file, 'r', encoding='utf-8') as file:\n            text = file.read()\n        \n        # Prepare sentences and chunks\n        sentences = improved_sentence_split(text)\n        chunks = [text[i:i+512] for i in range(0, len(text), 400) if len(text[i:i+512].strip()) > 50]\n        \n        # FinBERT sentence analysis\n        finbert_sentence_scores = []\n        for sentence in sentences:\n            if len(sentence.strip()) > 10:\n                score = analyze_with_model(finbert_analyzer, sentence)\n                finbert_sentence_scores.append(score)\n        finbert_sentences_avg = sum(finbert_sentence_scores) / len(finbert_sentence_scores) if finbert_sentence_scores else 0\n        \n        # FinBERT chunk analysis\n        finbert_chunk_scores = []\n        for chunk in chunks:\n            score = analyze_with_model(finbert_analyzer, chunk)\n            finbert_chunk_scores.append(score)\n        finbert_chunks_avg = sum(finbert_chunk_scores) / len(finbert_chunk_scores) if finbert_chunk_scores else 0\n        \n        # Financial-RoBERTa sentence analysis\n        roberta_sentence_scores = []\n        for sentence in sentences:\n            if len(sentence.strip()) > 10:\n                score = analyze_with_model(roberta_analyzer, sentence)\n                roberta_sentence_scores.append(score)\n        roberta_sentences_avg = sum(roberta_sentence_scores) / len(roberta_sentence_scores) if roberta_sentence_scores else 0\n        \n        # Financial-RoBERTa chunk analysis\n        roberta_chunk_scores = []\n        for chunk in chunks:\n            score = analyze_with_model(roberta_analyzer, chunk)\n            roberta_chunk_scores.append(score)\n        roberta_chunks_avg = sum(roberta_chunk_scores) / len(roberta_chunk_scores) if roberta_chunk_scores else 0\n        \n        # Store results\n        row = {\n            'Date': date_folder,\n            'FinBERT_Sentences': round(finbert_sentences_avg, 3),\n            'FinBERT_Chunks': round(finbert_chunks_avg, 3),\n            'RoBERTa_Sentences': round(roberta_sentences_avg, 3),\n            'RoBERTa_Chunks': round(roberta_chunks_avg, 3),\n            'Sentence_Count': len(finbert_sentence_scores),\n            'Chunk_Count': len(finbert_chunk_scores)\n        }\n        results.append(row)\n\n# Create DataFrame\ndf = pd.DataFrame(results)\n\n# CHRONOLOGICAL SORTING\ndef parse_date(date_str):\n    try:\n        parts = date_str.split('_')\n        if len(parts) == 3:\n            day, month, year = parts\n            return datetime.strptime(f\"{day} {month} {year}\", \"%d %B %Y\")\n        else:\n            return datetime.max\n    except:\n        return datetime.max\n\ndf['Parsed_Date'] = df['Date'].apply(parse_date)\ndf_sorted = df.sort_values('Parsed_Date').drop(columns=['Parsed_Date'])\n\n# Additional analysis: Consistency check\ndf_sorted['FinBERT_Difference'] = abs(df_sorted['FinBERT_Sentences'] - df_sorted['FinBERT_Chunks'])\ndf_sorted['RoBERTa_Difference'] = abs(df_sorted['RoBERTa_Sentences'] - df_sorted['RoBERTa_Chunks'])\n\n# ADD AVERAGE ROW\naverage_row = df_sorted.select_dtypes(include=['number']).mean()\naverage_row['Date'] = 'Average'\ndf_with_average = pd.concat([df_sorted, average_row.to_frame().T], ignore_index=True)\n\nprint(\"=== COMPLETE MODEL COMPARISON ===\")\nprint(df_with_average.to_string(index=False))\nprint(f\"FinBERT average difference sentences/chunks: {df_sorted['FinBERT_Difference'].mean():.3f}\")\nprint(f\"RoBERTa average difference sentences/chunks: {df_sorted['RoBERTa_Difference'].mean():.3f}\")\n\n# ===========================================\n# SAVE TO EXCEL WITH MULTIPLE SHEETS\n# ===========================================\n\n# Save main data to separate excel file\ndf_with_average.to_excel(CONFIG['main_excel_filename'], index=False)\n\n# Generate LaTeX table content WITH AVERAGE ROW\nlatex_table = df_with_average[['Date', 'FinBERT_Sentences', 'RoBERTa_Sentences', 'Sentence_Count']].to_latex(\n    index=False, \n    float_format=\"%.3f\",\n    caption=\"ECB Sentiment Analysis Results Comparison\",\n    label=\"tab:sentiment_comparison\",\n    column_format=\"llrr\"\n)\n\n# Generate summary report content\nreport = f\"\"\"ECB SENTIMENT ANALYSIS REPORT\n============================\n\nDataset Overview:\n- Total Documents Analyzed: {len(df_sorted)}\n- Date Range: {df_sorted['Date'].min()} to {df_sorted['Date'].max()}\n- Average Sentences per Document: {df_sorted['Sentence_Count'].mean():.1f}\n- Average Chunks per Document: {df_sorted['Chunk_Count'].mean():.1f}\n\nModel Performance Comparison:\n- FinBERT Average Sentiment (Sentences): {df_sorted['FinBERT_Sentences'].mean():.3f}\n- RoBERTa Average Sentiment (Sentences): {df_sorted['RoBERTa_Sentences'].mean():.3f}\n- Correlation between FinBERT and RoBERTa: {df_sorted['FinBERT_Sentences'].corr(df_sorted['RoBERTa_Sentences']):.3f}\n\nSentiment Range Analysis:\n- FinBERT Min/Max: {df_sorted['FinBERT_Sentences'].min():.3f} / {df_sorted['FinBERT_Sentences'].max():.3f}\n- RoBERTa Min/Max: {df_sorted['RoBERTa_Sentences'].min():.3f} / {df_sorted['RoBERTa_Sentences'].max():.3f}\n\nConsistency Analysis (Sentences vs Chunks):\n- FinBERT Consistency Score: {1 - df_sorted['FinBERT_Difference'].mean():.3f}\n- RoBERTa Consistency Score: {1 - df_sorted['RoBERTa_Difference'].mean():.3f}\n\nMost Positive Sentiment:\n- Date: {df_sorted.loc[df_sorted['FinBERT_Sentences'].idxmax(), 'Date']}\n- FinBERT Score: {df_sorted['FinBERT_Sentences'].max():.3f}\n\nMost Negative Sentiment:\n- Date: {df_sorted.loc[df_sorted['FinBERT_Sentences'].idxmin(), 'Date']}\n- FinBERT Score: {df_sorted['FinBERT_Sentences'].min():.3f}\"\"\"\n\n# Save Excel with multiple sheets\nwith pd.ExcelWriter(CONFIG['detailed_excel_filename'], engine='openpyxl') as writer:\n    # LaTeX table sheet\n    latex_df = pd.DataFrame([latex_table], columns=['LaTeX_Table'])\n    latex_df.to_excel(writer, sheet_name='LaTeX_Table', index=False, header=False)\n    \n    # Summary report sheet\n    report_df = pd.DataFrame([report], columns=['Summary_Report'])\n    report_df.to_excel(writer, sheet_name='Summary_Report', index=False, header=False)\n\nprint(f\"\\n✅ Main data saved: {CONFIG['main_excel_filename']}\")\nprint(f\"✅ Detailed analysis saved: {CONFIG['detailed_excel_filename']}\")\nprint(\"Sheets: LaTeX_Table, Summary_Report\")\n\n# Download link\ndisplay(FileLink(CONFIG['main_excel_filename']))\ndisplay(FileLink(CONFIG['detailed_excel_filename']))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:45:23.650201Z","iopub.execute_input":"2025-07-02T20:45:23.650488Z","iopub.status.idle":"2025-07-02T20:47:12.167933Z","shell.execute_reply.started":"2025-07-02T20:45:23.650469Z","shell.execute_reply":"2025-07-02T20:47:12.167301Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nDevice set to use cuda:0\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Processing: 17_October_2024\nProcessing: 17_April_2025\nProcessing: 14_December_2023\nProcessing: 11_April_2024\nProcessing: 12_December_2024\nProcessing: 21_July_2022\nProcessing: 08_September_2022\nProcessing: 14_September_2023\nProcessing: 12_September_2024\nProcessing: 07_March_2024\nProcessing: 27_October_2022\nProcessing: 16_March_2023\nProcessing: 06_March_2025\nProcessing: 26_October_2023\nProcessing: 27_July_2023\nProcessing: 25_January_2024\nProcessing: 02_February_2023\nProcessing: 30_January_2025\nProcessing: 18_July_2024\nProcessing: 05_June_2025\nProcessing: 09_June_2022\nProcessing: 15_December_2022\nProcessing: 15_June_2023\nProcessing: 04_May_2023\nProcessing: 06_June_2024\n=== COMPLETE MODEL COMPARISON ===\n             Date FinBERT_Sentences FinBERT_Chunks RoBERTa_Sentences RoBERTa_Chunks Sentence_Count Chunk_Count FinBERT_Difference RoBERTa_Difference\n     09_June_2022             0.196          0.119             0.036         -0.069            123          46              0.077              0.105\n     21_July_2022              0.26          0.245             0.094          0.231            104          39              0.015              0.137\n08_September_2022             0.012         -0.006            -0.174         -0.245             98          39              0.018              0.071\n  27_October_2022              0.07          0.096            -0.058         -0.004             94          36              0.026              0.054\n 15_December_2022            -0.024         -0.195            -0.102          -0.14            113          45              0.171              0.038\n 02_February_2023             0.106          0.003             0.059          0.069            102          41              0.103               0.01\n    16_March_2023             0.077           0.03            -0.105         -0.073             98          39              0.047              0.032\n      04_May_2023             0.044          0.088            -0.015         -0.229             92          36              0.044              0.214\n     15_June_2023            -0.117          -0.27            -0.167          -0.24            109          40              0.153              0.073\n     27_July_2023             0.026         -0.018             0.016         -0.085             93          37              0.044              0.101\n14_September_2023            -0.021         -0.126             0.038         -0.175             98          37              0.105              0.213\n  26_October_2023            -0.066         -0.142            -0.114         -0.161            102          34              0.076              0.047\n 14_December_2023            -0.016         -0.255            -0.061         -0.178            116          41              0.239              0.117\n  25_January_2024            -0.053         -0.185            -0.032         -0.178             78          30              0.132              0.146\n    07_March_2024            -0.032          -0.23             0.015         -0.027             88          33              0.198              0.042\n    11_April_2024             0.044         -0.191             0.091         -0.056             83          33              0.235              0.147\n     06_June_2024             0.127         -0.084             0.081          0.119            106          38              0.211              0.038\n     18_July_2024             0.047         -0.113            -0.074         -0.255             88          32               0.16              0.181\n12_September_2024            -0.048         -0.387            -0.042         -0.055            117          41              0.339              0.013\n  17_October_2024             0.037         -0.283             -0.08         -0.108             98          34               0.32              0.028\n 12_December_2024             0.092         -0.103             0.058          0.133            116          40              0.195              0.075\n  30_January_2025              0.15          0.059             0.002          -0.02             95          35              0.091              0.022\n    06_March_2025             0.052         -0.141            -0.064         -0.091            101          35              0.193              0.027\n    17_April_2025            -0.095          -0.41            -0.036          0.064             94          35              0.315                0.1\n     05_June_2025             0.118         -0.095             0.031         -0.043            107          42              0.213              0.074\n          Average           0.03944       -0.10376          -0.02412       -0.07264         100.52       37.52             0.1488             0.0842\nFinBERT average difference sentences/chunks: 0.149\nRoBERTa average difference sentences/chunks: 0.084\n\n✅ Main data saved: ecb_sentiment_analysis.xlsx\n✅ Detailed analysis saved: sentiment_analysis_details.xlsx\nSheets: LaTeX_Table, Summary_Report\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/ecb_sentiment_analysis.xlsx","text/html":"<a href='ecb_sentiment_analysis.xlsx' target='_blank'>ecb_sentiment_analysis.xlsx</a><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/sentiment_analysis_details.xlsx","text/html":"<a href='sentiment_analysis_details.xlsx' target='_blank'>sentiment_analysis_details.xlsx</a><br>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"#NEU TRY\n\n#complete Evaluation LLM Models\nfrom transformers import pipeline\nimport os\nimport pandas as pd\nfrom datetime import datetime\nfrom IPython.display import FileLink\nimport nltk\nfrom nltk.tokenize.punkt import PunktSentenceTokenizer, PunktParameters\n\n# Download NLTK Punkt data (one-time)\nnltk.download('punkt')\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\nCONFIG = {\n    'main_excel_filename': 'ecb_sentiment_analysis_sum.xlsx',            \n    'detailed_excel_filename': 'sentiment_analysis_details_sum.xlsx'\n}\n\n# OPTION: Enable/disable output\nSHOW_PROGRESS = True\n\n# Load both models\nfinbert_analyzer = pipeline(\"text-classification\", model=\"ProsusAI/finbert\", top_k=None)\nroberta_analyzer = pipeline(\"text-classification\", model=\"soleimanian/financial-roberta-large-sentiment\", top_k=None)\n\n# Path to folders\ninput_folder = \"/kaggle/input/llm-text/TEXT/EZB/\"\n\n# Process all date folders\ndate_folders = [f for f in os.listdir(input_folder) if os.path.isdir(os.path.join(input_folder, f))]\n\nresults = []\n\ndef improved_sentence_split(text):\n    # Punkt parameters for ECB-specific abbreviations\n    punkt_param = PunktParameters()\n    punkt_param.abbrev_types = set([\n        'mr', 'mrs', 'ms', 'dr', 'prof',  # Titles\n        'e.g', 'i.e', 'etc', 'vs', 'cf',  # Latin abbreviations\n        'ecb', 'eu', 'euro', 'gdp', 'cpi', 'ppp',  # Financial abbreviations\n        'u.s', 'u.k', 'u.s.a', 'e.u',  # Countries\n        'jan', 'feb', 'mar', 'apr', 'may', 'jun',  # Months\n        'jul', 'aug', 'sep', 'oct', 'nov', 'dec',\n        'inc', 'ltd', 'corp', 'co', 'llc',  # Companies\n        'no', 'nos', 'vol', 'p', 'pp', 'fig',  # General abbreviations\n        'tel', 'fax', 'email', 'www'  # Contact abbreviations\n    ])\n    \n    # Tokenizer with adjusted parameters\n    tokenizer = PunktSentenceTokenizer(punkt_param)\n    \n    # Split text into sentences\n    sentences = tokenizer.tokenize(text)\n    \n    # Filter short sentences and clean\n    sentences = [s.strip() for s in sentences if len(s.strip()) > 20]\n    \n    return sentences\n\ndef analyze_with_model(analyzer, text_input):\n    \"\"\"Helper function for sentiment analysis\"\"\"\n    result = analyzer(text_input)\n    neg_prob = next(r['score'] for r in result[0] if r['label'] == 'negative')\n    pos_prob = next(r['score'] for r in result[0] if r['label'] == 'positive')\n    return pos_prob - neg_prob\n\n\n\nfor date_folder in date_folders:\n    full_file = os.path.join(input_folder, date_folder, \"0_FULL.txt\")\n    \n    if os.path.exists(full_file):\n        if SHOW_PROGRESS:\n            print(f\"Processing: {date_folder}\")\n        \n        # Read file\n        with open(full_file, 'r', encoding='utf-8') as file:\n            text = file.read()\n        \n        # Prepare sentences and chunks\n        sentences = improved_sentence_split(text)\n        chunks = [text[i:i+512] for i in range(0, len(text), 400) if len(text[i:i+512].strip()) > 50]\n        \n        # FinBERT sentence analysis\n        finbert_sentence_scores = []\n        for sentence in sentences:\n            if len(sentence.strip()) > 10:\n                score = analyze_with_model(finbert_analyzer, sentence)\n                finbert_sentence_scores.append(score)\n        finbert_sentences_avg = sum(finbert_sentence_scores) / len(finbert_sentence_scores) if finbert_sentence_scores else 0\n        finbert_sentences_sum = sum(finbert_sentence_scores) if finbert_sentence_scores else 0\n        \n        # FinBERT chunk analysis\n        finbert_chunk_scores = []\n        for chunk in chunks:\n            score = analyze_with_model(finbert_analyzer, chunk)\n            finbert_chunk_scores.append(score)\n        finbert_chunks_avg = sum(finbert_chunk_scores) / len(finbert_chunk_scores) if finbert_chunk_scores else 0\n        finbert_chunks_sum = sum(finbert_chunk_scores) if finbert_chunk_scores else 0\n        \n        # Financial-RoBERTa sentence analysis\n        roberta_sentence_scores = []\n        for sentence in sentences:\n            if len(sentence.strip()) > 10:\n                score = analyze_with_model(roberta_analyzer, sentence)\n                roberta_sentence_scores.append(score)\n        roberta_sentences_avg = sum(roberta_sentence_scores) / len(roberta_sentence_scores) if roberta_sentence_scores else 0\n        roberta_sentences_sum = sum(roberta_sentence_scores) if roberta_sentence_scores else 0\n        \n        # Financial-RoBERTa chunk analysis\n        roberta_chunk_scores = []\n        for chunk in chunks:\n            score = analyze_with_model(roberta_analyzer, chunk)\n            roberta_chunk_scores.append(score)\n        roberta_chunks_avg = sum(roberta_chunk_scores) / len(roberta_chunk_scores) if roberta_chunk_scores else 0\n        roberta_chunks_sum = sum(roberta_chunk_scores) if roberta_chunk_scores else 0\n        \n        # Store results with BOTH average AND sum\n        row = {\n            'Date': date_folder,\n            'FinBERT_Sentences_Avg': round(finbert_sentences_avg, 3),\n            'FinBERT_Sentences_Sum': round(finbert_sentences_sum, 3),\n            'FinBERT_Chunks_Avg': round(finbert_chunks_avg, 3),\n            'FinBERT_Chunks_Sum': round(finbert_chunks_sum, 3),\n            'RoBERTa_Sentences_Avg': round(roberta_sentences_avg, 3),\n            'RoBERTa_Sentences_Sum': round(roberta_sentences_sum, 3),\n            'RoBERTa_Chunks_Avg': round(roberta_chunks_avg, 3),\n            'RoBERTa_Chunks_Sum': round(roberta_chunks_sum, 3),\n            'Sentence_Count': len(finbert_sentence_scores),\n            'Chunk_Count': len(finbert_chunk_scores)\n        }\n        results.append(row)\n\n# Create DataFrame\ndf = pd.DataFrame(results)\n\n# CHRONOLOGICAL SORTING\ndef parse_date(date_str):\n    try:\n        parts = date_str.split('_')\n        if len(parts) == 3:\n            day, month, year = parts\n            return datetime.strptime(f\"{day} {month} {year}\", \"%d %B %Y\")\n        else:\n            return datetime.max\n    except:\n        return datetime.max\n\ndf['Parsed_Date'] = df['Date'].apply(parse_date)\ndf_sorted = df.sort_values('Parsed_Date').drop(columns=['Parsed_Date'])\n\n# Additional analysis: Consistency check (updated for new column names)\ndf_sorted['FinBERT_Difference'] = abs(df_sorted['FinBERT_Sentences_Avg'] - df_sorted['FinBERT_Chunks_Avg'])\ndf_sorted['RoBERTa_Difference'] = abs(df_sorted['RoBERTa_Sentences_Avg'] - df_sorted['RoBERTa_Chunks_Avg'])\n\n# ADD AVERAGE ROW\naverage_row = df_sorted.select_dtypes(include=['number']).mean()\naverage_row['Date'] = 'Average'\ndf_with_average = pd.concat([df_sorted, average_row.to_frame().T], ignore_index=True)\n\nprint(\"=== COMPLETE MODEL COMPARISON (AVG + SUM) ===\")\nprint(df_with_average.to_string(index=False))\nprint(f\"FinBERT average difference sentences/chunks: {df_sorted['FinBERT_Difference'].mean():.3f}\")\nprint(f\"RoBERTa average difference sentences/chunks: {df_sorted['RoBERTa_Difference'].mean():.3f}\")\n\n# ===========================================\n# SAVE TO EXCEL WITH MULTIPLE SHEETS\n# ===========================================\n\n# Save main data to separate excel file\ndf_with_average.to_excel(CONFIG['main_excel_filename'], index=False)\n\n# Generate LaTeX table content WITH AVERAGE ROW (updated for new columns)\nlatex_table = df_with_average[['Date', 'FinBERT_Sentences_Avg', 'FinBERT_Sentences_Sum', 'RoBERTa_Sentences_Avg', 'RoBERTa_Sentences_Sum', 'Sentence_Count']].to_latex(\n    index=False, \n    float_format=\"%.3f\",\n    caption=\"ECB Sentiment Analysis Results Comparison (Average and Sum)\",\n    label=\"tab:sentiment_comparison\",\n    column_format=\"lrrrrr\"\n)\n\n# Generate summary report content (updated for new columns)\nreport = f\"\"\"ECB SENTIMENT ANALYSIS REPORT (AVG + SUM)\n==========================================\n\nDataset Overview:\n- Total Documents Analyzed: {len(df_sorted)}\n- Date Range: {df_sorted['Date'].min()} to {df_sorted['Date'].max()}\n- Average Sentences per Document: {df_sorted['Sentence_Count'].mean():.1f}\n- Average Chunks per Document: {df_sorted['Chunk_Count'].mean():.1f}\n\nModel Performance Comparison (AVERAGES):\n- FinBERT Average Sentiment (Sentences): {df_sorted['FinBERT_Sentences_Avg'].mean():.3f}\n- RoBERTa Average Sentiment (Sentences): {df_sorted['RoBERTa_Sentences_Avg'].mean():.3f}\n- Correlation between FinBERT and RoBERTa: {df_sorted['FinBERT_Sentences_Avg'].corr(df_sorted['RoBERTa_Sentences_Avg']):.3f}\n\nModel Performance Comparison (SUMS):\n- FinBERT Average Sum (Sentences): {df_sorted['FinBERT_Sentences_Sum'].mean():.3f}\n- RoBERTa Average Sum (Sentences): {df_sorted['RoBERTa_Sentences_Sum'].mean():.3f}\n- Correlation between FinBERT and RoBERTa Sums: {df_sorted['FinBERT_Sentences_Sum'].corr(df_sorted['RoBERTa_Sentences_Sum']):.3f}\n\nSentiment Range Analysis (AVERAGES):\n- FinBERT Min/Max: {df_sorted['FinBERT_Sentences_Avg'].min():.3f} / {df_sorted['FinBERT_Sentences_Avg'].max():.3f}\n- RoBERTa Min/Max: {df_sorted['RoBERTa_Sentences_Avg'].min():.3f} / {df_sorted['RoBERTa_Sentences_Avg'].max():.3f}\n\nSentiment Range Analysis (SUMS):\n- FinBERT Sum Min/Max: {df_sorted['FinBERT_Sentences_Sum'].min():.3f} / {df_sorted['FinBERT_Sentences_Sum'].max():.3f}\n- RoBERTa Sum Min/Max: {df_sorted['RoBERTa_Sentences_Sum'].min():.3f} / {df_sorted['RoBERTa_Sentences_Sum'].max():.3f}\n\nConsistency Analysis (Sentences vs Chunks):\n- FinBERT Consistency Score: {1 - df_sorted['FinBERT_Difference'].mean():.3f}\n- RoBERTa Consistency Score: {1 - df_sorted['RoBERTa_Difference'].mean():.3f}\n\nMost Positive Sentiment (AVG):\n- Date: {df_sorted.loc[df_sorted['FinBERT_Sentences_Avg'].idxmax(), 'Date']}\n- FinBERT Score: {df_sorted['FinBERT_Sentences_Avg'].max():.3f}\n\nMost Negative Sentiment (AVG):\n- Date: {df_sorted.loc[df_sorted['FinBERT_Sentences_Avg'].idxmin(), 'Date']}\n- FinBERT Score: {df_sorted['FinBERT_Sentences_Avg'].min():.3f}\n\nHighest Total Sentiment (SUM):\n- Date: {df_sorted.loc[df_sorted['FinBERT_Sentences_Sum'].idxmax(), 'Date']}\n- FinBERT Sum: {df_sorted['FinBERT_Sentences_Sum'].max():.3f}\"\"\"\n\n# Save Excel with multiple sheets\nwith pd.ExcelWriter(CONFIG['detailed_excel_filename'], engine='openpyxl') as writer:\n    # LaTeX table sheet\n    latex_df = pd.DataFrame([latex_table], columns=['LaTeX_Table'])\n    latex_df.to_excel(writer, sheet_name='LaTeX_Table', index=False, header=False)\n    \n    # Summary report sheet\n    report_df = pd.DataFrame([report], columns=['Summary_Report'])\n    report_df.to_excel(writer, sheet_name='Summary_Report', index=False, header=False)\n\nprint(f\"\\n✅ Main data saved: {CONFIG['main_excel_filename']}\")\nprint(f\"✅ Detailed analysis saved: {CONFIG['detailed_excel_filename']}\")\nprint(\"Sheets: LaTeX_Table, Summary_Report\")\n\n# Download link\ndisplay(FileLink(CONFIG['main_excel_filename']))\ndisplay(FileLink(CONFIG['detailed_excel_filename']))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:47:12.169956Z","iopub.execute_input":"2025-07-02T20:47:12.170170Z","iopub.status.idle":"2025-07-02T20:49:00.875934Z","shell.execute_reply.started":"2025-07-02T20:47:12.170154Z","shell.execute_reply":"2025-07-02T20:49:00.875276Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nDevice set to use cuda:0\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Processing: 17_October_2024\nProcessing: 17_April_2025\nProcessing: 14_December_2023\nProcessing: 11_April_2024\nProcessing: 12_December_2024\nProcessing: 21_July_2022\nProcessing: 08_September_2022\nProcessing: 14_September_2023\nProcessing: 12_September_2024\nProcessing: 07_March_2024\nProcessing: 27_October_2022\nProcessing: 16_March_2023\nProcessing: 06_March_2025\nProcessing: 26_October_2023\nProcessing: 27_July_2023\nProcessing: 25_January_2024\nProcessing: 02_February_2023\nProcessing: 30_January_2025\nProcessing: 18_July_2024\nProcessing: 05_June_2025\nProcessing: 09_June_2022\nProcessing: 15_December_2022\nProcessing: 15_June_2023\nProcessing: 04_May_2023\nProcessing: 06_June_2024\n=== COMPLETE MODEL COMPARISON (AVG + SUM) ===\n             Date FinBERT_Sentences_Avg FinBERT_Sentences_Sum FinBERT_Chunks_Avg FinBERT_Chunks_Sum RoBERTa_Sentences_Avg RoBERTa_Sentences_Sum RoBERTa_Chunks_Avg RoBERTa_Chunks_Sum Sentence_Count Chunk_Count FinBERT_Difference RoBERTa_Difference\n     09_June_2022                 0.196                 24.12              0.119              5.461                 0.036                  4.46             -0.069             -3.163            123          46              0.077              0.105\n     21_July_2022                  0.26                27.056              0.245              9.568                 0.094                 9.738              0.231               8.99            104          39              0.015              0.137\n08_September_2022                 0.012                 1.137             -0.006             -0.239                -0.174               -17.095             -0.245             -9.543             98          39              0.018              0.071\n  27_October_2022                  0.07                 6.566              0.096              3.465                -0.058                -5.494             -0.004              -0.15             94          36              0.026              0.054\n 15_December_2022                -0.024                -2.672             -0.195             -8.784                -0.102               -11.493              -0.14             -6.291            113          45              0.171              0.038\n 02_February_2023                 0.106                10.818              0.003              0.116                 0.059                 5.998              0.069               2.81            102          41              0.103               0.01\n    16_March_2023                 0.077                 7.582               0.03              1.152                -0.105               -10.252             -0.073             -2.851             98          39              0.047              0.032\n      04_May_2023                 0.044                 4.058              0.088              3.163                -0.015                -1.391             -0.229             -8.239             92          36              0.044              0.214\n     15_June_2023                -0.117               -12.753              -0.27            -10.781                -0.167               -18.149              -0.24             -9.604            109          40              0.153              0.073\n     27_July_2023                 0.026                 2.409             -0.018              -0.66                 0.016                 1.499             -0.085             -3.152             93          37              0.044              0.101\n14_September_2023                -0.021                -2.051             -0.126             -4.678                 0.038                 3.704             -0.175             -6.482             98          37              0.105              0.213\n  26_October_2023                -0.066                -6.747             -0.142             -4.835                -0.114               -11.623             -0.161             -5.485            102          34              0.076              0.047\n 14_December_2023                -0.016                  -1.9             -0.255             -10.46                -0.061                -7.028             -0.178             -7.308            116          41              0.239              0.117\n  25_January_2024                -0.053                -4.137             -0.185             -5.553                -0.032                -2.532             -0.178             -5.351             78          30              0.132              0.146\n    07_March_2024                -0.032                -2.807              -0.23             -7.586                 0.015                  1.35             -0.027             -0.875             88          33              0.198              0.042\n    11_April_2024                 0.044                 3.612             -0.191             -6.298                 0.091                 7.529             -0.056             -1.851             83          33              0.235              0.147\n     06_June_2024                 0.127                13.448             -0.084             -3.197                 0.081                 8.585              0.119              4.537            106          38              0.211              0.038\n     18_July_2024                 0.047                 4.098             -0.113             -3.602                -0.074                -6.519             -0.255             -8.165             88          32               0.16              0.181\n12_September_2024                -0.048                -5.644             -0.387            -15.878                -0.042                -4.928             -0.055             -2.271            117          41              0.339              0.013\n  17_October_2024                 0.037                 3.662             -0.283              -9.61                 -0.08                -7.812             -0.108              -3.68             98          34               0.32              0.028\n 12_December_2024                 0.092                10.646             -0.103             -4.122                 0.058                 6.725              0.133              5.309            116          40              0.195              0.075\n  30_January_2025                  0.15                14.293              0.059              2.066                 0.002                 0.213              -0.02             -0.684             95          35              0.091              0.022\n    06_March_2025                 0.052                 5.235             -0.141             -4.948                -0.064                -6.444             -0.091              -3.19            101          35              0.193              0.027\n    17_April_2025                -0.095                -8.927              -0.41            -14.334                -0.036                -3.416              0.064              2.249             94          35              0.315                0.1\n     05_June_2025                 0.118                12.669             -0.095             -3.978                 0.031                  3.32             -0.043             -1.807            107          42              0.213              0.074\n          Average               0.03944               4.15084           -0.10376           -3.78208              -0.02412               -2.4422           -0.07264           -2.64988         100.52       37.52             0.1488             0.0842\nFinBERT average difference sentences/chunks: 0.149\nRoBERTa average difference sentences/chunks: 0.084\n\n✅ Main data saved: ecb_sentiment_analysis_sum.xlsx\n✅ Detailed analysis saved: sentiment_analysis_details_sum.xlsx\nSheets: LaTeX_Table, Summary_Report\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/ecb_sentiment_analysis_sum.xlsx","text/html":"<a href='ecb_sentiment_analysis_sum.xlsx' target='_blank'>ecb_sentiment_analysis_sum.xlsx</a><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/sentiment_analysis_details_sum.xlsx","text/html":"<a href='sentiment_analysis_details_sum.xlsx' target='_blank'>sentiment_analysis_details_sum.xlsx</a><br>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import pipeline\n\ndef test_model_labels():\n    \"\"\"Test function to check the exact labels used by both models\"\"\"\n    \n    # Load both models\n    print(\"🔄 Loading models...\")\n    finbert_analyzer = pipeline(\"text-classification\", model=\"ProsusAI/finbert\", top_k=None)\n    roberta_analyzer = pipeline(\"text-classification\", model=\"soleimanian/financial-roberta-large-sentiment\", top_k=None)\n    \n    # Test text\n    sample_text = \"The company's revenue increased significantly this quarter, showing strong growth.\"\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"📊 TESTING MODEL LABELS\")\n    print(\"=\"*60)\n    \n    # Test FinBERT\n    print(\"\\n🔍 FINBERT MODEL:\")\n    print(\"-\" * 30)\n    finbert_result = finbert_analyzer(sample_text)\n    print(f\"Raw output: {finbert_result}\")\n    \n    finbert_labels = {r['label']: r['score'] for r in finbert_result[0]}\n    print(f\"Available labels: {list(finbert_labels.keys())}\")\n    print(f\"Label-Score mapping: {finbert_labels}\")\n    \n    # Test RoBERTa\n    print(\"\\n🔍 ROBERTA MODEL:\")\n    print(\"-\" * 30)\n    roberta_result = roberta_analyzer(sample_text)\n    print(f\"Raw output: {roberta_result}\")\n    \n    roberta_labels = {r['label']: r['score'] for r in roberta_result[0]}\n    print(f\"Available labels: {list(roberta_labels.keys())}\")\n    print(f\"Label-Score mapping: {roberta_labels}\")\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"📋 SUMMARY:\")\n    print(\"=\"*60)\n    print(f\"FinBERT labels: {list(finbert_labels.keys())}\")\n    print(f\"RoBERTa labels: {list(roberta_labels.keys())}\")\n    \n    return finbert_labels, roberta_labels\n\n# Korrigierte analyze_with_model Funktion basierend auf den Ergebnissen\ndef analyze_with_model_corrected(analyzer, text_input, model_type=\"finbert\"):\n    \"\"\"Helper function for sentiment analysis with correct labels\"\"\"\n    result = analyzer(text_input)\n    labels = {r['label']: r['score'] for r in result[0]}\n    \n    if model_type.lower() == \"finbert\":\n        # FinBERT verwendet lowercase labels\n        neg_prob = labels.get('negative')\n        pos_prob = labels.get('positive')\n    else:  # roberta\n        # RoBERTa verwendet capitalized labels\n        neg_prob = labels.get('negative')\n        pos_prob = labels.get('positive')\n    \n    return pos_prob - neg_prob\n\n# Teste die Labels\nif __name__ == \"__main__\":\n    finbert_labels, roberta_labels = test_model_labels()\n    \n    # Teste die korrigierte Funktion\n    print(\"\\n🧪 TESTING CORRECTED FUNCTION:\")\n    print(\"-\" * 40)\n    \n    # Load models again for testing\n    finbert_analyzer = pipeline(\"text-classification\", model=\"ProsusAI/finbert\", top_k=None)\n    roberta_analyzer = pipeline(\"text-classification\", model=\"soleimanian/financial-roberta-large-sentiment\", top_k=None)\n    \n    test_text = \"The market outlook is very positive with strong growth expected.\"\n    \n    finbert_score = analyze_with_model_corrected(finbert_analyzer, test_text, \"finbert\")\n    roberta_score = analyze_with_model_corrected(roberta_analyzer, test_text, \"roberta\")\n    \n    print(f\"FinBERT sentiment score: {finbert_score:.4f}\")\n    print(f\"RoBERTa sentiment score: {roberta_score:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T20:49:00.876754Z","iopub.execute_input":"2025-07-02T20:49:00.876957Z","iopub.status.idle":"2025-07-02T20:49:05.652413Z","shell.execute_reply.started":"2025-07-02T20:49:00.876941Z","shell.execute_reply":"2025-07-02T20:49:05.651667Z"}},"outputs":[{"name":"stdout","text":"🔄 Loading models...\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cuda:0\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\n📊 TESTING MODEL LABELS\n============================================================\n\n🔍 FINBERT MODEL:\n------------------------------\nRaw output: [[{'label': 'positive', 'score': 0.9563620090484619}, {'label': 'neutral', 'score': 0.02615462802350521}, {'label': 'negative', 'score': 0.017483336851000786}]]\nAvailable labels: ['positive', 'neutral', 'negative']\nLabel-Score mapping: {'positive': 0.9563620090484619, 'neutral': 0.02615462802350521, 'negative': 0.017483336851000786}\n\n🔍 ROBERTA MODEL:\n------------------------------\nRaw output: [[{'label': 'positive', 'score': 0.9982404708862305}, {'label': 'negative', 'score': 0.000943619990721345}, {'label': 'neutral', 'score': 0.0008159285644069314}]]\nAvailable labels: ['positive', 'negative', 'neutral']\nLabel-Score mapping: {'positive': 0.9982404708862305, 'negative': 0.000943619990721345, 'neutral': 0.0008159285644069314}\n\n============================================================\n📋 SUMMARY:\n============================================================\nFinBERT labels: ['positive', 'neutral', 'negative']\nRoBERTa labels: ['positive', 'negative', 'neutral']\n\n🧪 TESTING CORRECTED FUNCTION:\n----------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cuda:0\nDevice set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"FinBERT sentiment score: 0.9334\nRoBERTa sentiment score: 0.9975\n","output_type":"stream"}],"execution_count":29}]}